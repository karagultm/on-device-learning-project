
Sensor Data:
Total data count: 100
1 - User: 33, Activity: Jogging, Timestamp: 49105962326000, X: -0.694638, Y: 12.680544, Z: 0.503953
2 - User: 33, Activity: Jogging, Timestamp: 49106062271000, X: 5.012288, Y: 11.264028, Z: 0.953424
3 - User: 33, Activity: Jogging, Timestamp: 49106112167000, X: 4.903325, Y: 10.882658, Z: -0.081722
4 - User: 33, Activity: Jogging, Timestamp: 49106222305000, X: -0.612916, Y: 18.496431, Z: 3.023717
5 - User: 33, Activity: Jogging, Timestamp: 49106332290000, X: -1.184970, Y: 12.108489, Z: 7.205164
6 - User: 33, Activity: Jogging, Timestamp: 49106442306000, X: 1.375655, Y: -2.492524, Z: -6.510526
7 - User: 33, Activity: Jogging, Timestamp: 49106542312000, X: -0.612916, Y: 10.569390, Z: 5.706926
8 - User: 33, Activity: Jogging, Timestamp: 49106652389000, X: -0.503953, Y: 13.947236, Z: 7.055340
9 - User: 33, Activity: Jogging, Timestamp: 49106762313000, X: -8.430995, Y: 11.413852, Z: 5.134871
10 - User: 33, Activity: Jogging, Timestamp: 49106872299000, X: 0.953424, Y: 1.375655, Z: 1.648062
11 - User: 33, Activity: Jogging, Timestamp: 49106982315000, X: -8.199450, Y: 19.572440, Z: 2.724070
12 - User: 33, Activity: Jogging, Timestamp: 49107092330000, X: 1.416516, Y: 5.788648, Z: 2.982856
13 - User: 33, Activity: Jogging, Timestamp: 49107202316000, X: -1.879608, Y: -2.982856, Z: -0.299648
14 - User: 33, Activity: Jogging, Timestamp: 49107312332000, X: -6.129157, Y: 6.851035, Z: -8.158588
15 - User: 33, Activity: Jogging, Timestamp: 49107422348000, X: 5.829509, Y: 18.006100, Z: 8.539958
16 - User: 33, Activity: Jogging, Timestamp: 49107522293000, X: 6.278980, Y: 2.982856, Z: 2.914754
17 - User: 33, Activity: Jogging, Timestamp: 49107632339000, X: -1.566340, Y: 8.308413, Z: -1.457377
18 - User: 33, Activity: Jogging, Timestamp: 49107742355000, X: 3.527670, Y: 13.593107, Z: 9.425281
19 - User: 33, Activity: Jogging, Timestamp: 49107852340000, X: -2.029432, Y: -5.706926, Z: -10.188020
20 - User: 33, Activity: Jogging, Timestamp: 49107962326000, X: 2.764931, Y: 10.337844, Z: -9.724928
21 - User: 33, Activity: Jogging, Timestamp: 49108062271000, X: 3.568531, Y: 13.674829, Z: 1.539099
22 - User: 33, Activity: Jogging, Timestamp: 49108172348000, X: -0.503953, Y: 3.868179, Z: 3.718355
23 - User: 33, Activity: Jogging, Timestamp: 49108272262000, X: -2.301839, Y: 1.688923, Z: 0.081722
24 - User: 33, Activity: Jogging, Timestamp: 49108382370000, X: -3.568531, Y: 19.572440, Z: 6.510526
25 - User: 33, Activity: Jogging, Timestamp: 49108492294000, X: -0.803601, Y: -3.296124, Z: -4.630918
26 - User: 33, Activity: Jogging, Timestamp: 49108602371000, X: 0.503953, Y: 10.841797, Z: 13.525005
27 - User: 33, Activity: Jogging, Timestamp: 49108702285000, X: 5.706926, Y: 15.595298, Z: 6.170018
28 - User: 33, Activity: Jogging, Timestamp: 49108812332000, X: -8.662541, Y: 7.273266, Z: 4.018002
29 - User: 33, Activity: Jogging, Timestamp: 49108922378000, X: -1.334794, Y: 1.225831, Z: 2.369940
30 - User: 33, Activity: Jogging, Timestamp: 49109022293000, X: -4.590057, Y: 19.572440, Z: 4.712640
31 - User: 33, Activity: Jogging, Timestamp: 49109132308000, X: 3.868179, Y: 3.759216, Z: 0.844462
32 - User: 33, Activity: Jogging, Timestamp: 49109242355000, X: -1.797886, Y: 1.539099, Z: 8.730643
33 - User: 33, Activity: Jogging, Timestamp: 49109352310000, X: 7.668256, Y: 11.264028, Z: -1.307553
34 - User: 33, Activity: Jogging, Timestamp: 49109462295000, X: -2.369940, Y: 14.287745, Z: 8.281172
35 - User: 33, Activity: Jogging, Timestamp: 49109562271000, X: 2.724070, Y: 1.457377, Z: 0.885323
36 - User: 33, Activity: Jogging, Timestamp: 49109672348000, X: -3.595772, Y: 18.659876, Z: -0.653777
37 - User: 33, Activity: Jogging, Timestamp: 49109782333000, X: 3.949901, Y: 4.140586, Z: 3.990762
38 - User: 33, Activity: Jogging, Timestamp: 49109892349000, X: 0.463092, Y: -2.410802, Z: 2.410802
39 - User: 33, Activity: Jogging, Timestamp: 49109992263000, X: 3.786457, Y: 14.137921, Z: -3.146300
40 - User: 33, Activity: Jogging, Timestamp: 49110102371000, X: 3.336985, Y: 19.231932, Z: 6.551387
41 - User: 33, Activity: Jogging, Timestamp: 49110212326000, X: 5.666065, Y: 3.786457, Z: 0.531194
42 - User: 33, Activity: Jogging, Timestamp: 49110263595000, X: 0.231546, Y: 0.762740, Z: 0.762740
43 - User: 33, Activity: Jogging, Timestamp: 49110372299000, X: -4.821603, Y: 19.572440, Z: 8.158588
44 - User: 33, Activity: Jogging, Timestamp: 49110482345000, X: 1.838747, Y: -1.116869, Z: -2.792171
45 - User: 33, Activity: Jogging, Timestamp: 49110582290000, X: -3.296124, Y: 10.079058, Z: 13.824653
46 - User: 33, Activity: Jogging, Timestamp: 49110692306000, X: 11.604536, Y: 17.079916, Z: 1.334794
47 - User: 33, Activity: Jogging, Timestamp: 49110802291000, X: -3.173541, Y: 14.015338, Z: 5.706926
48 - User: 33, Activity: Jogging, Timestamp: 49110912307000, X: 0.612916, Y: 1.116869, Z: 2.560625
49 - User: 33, Activity: Jogging, Timestamp: 49111012222000, X: -7.886181, Y: 19.572440, Z: 1.988571
50 - User: 33, Activity: Jogging, Timestamp: 49111112289000, X: 3.146300, Y: 5.243834, Z: 4.671779
51 - User: 33, Activity: Jogging, Timestamp: 49111222305000, X: -3.023717, Y: -4.331271, Z: -3.336985
52 - User: 33, Activity: Jogging, Timestamp: 49111332290000, X: -0.081722, Y: 11.917805, Z: -7.886181
53 - User: 33, Activity: Jogging, Timestamp: 49111392257000, X: -1.035146, Y: 14.818938, Z: 4.603678
54 - User: 33, Activity: Jogging, Timestamp: 49111502304000, X: -2.451662, Y: 2.533385, Z: 3.486809
55 - User: 33, Activity: Jogging, Timestamp: 49111612289000, X: -1.375655, Y: 2.070293, Z: -0.190685
56 - User: 33, Activity: Jogging, Timestamp: 49111722335000, X: -2.492524, Y: 19.572440, Z: 6.469665
57 - User: 33, Activity: Jogging, Timestamp: 49111832290000, X: 1.457377, Y: -5.243834, Z: -4.372132
58 - User: 33, Activity: Jogging, Timestamp: 49111942337000, X: -1.416516, Y: 9.806650, Z: 5.747787
59 - User: 33, Activity: Jogging, Timestamp: 49112042282000, X: -1.266692, Y: 14.709975, Z: 6.210878
60 - User: 33, Activity: Jogging, Timestamp: 49112152297000, X: -3.677494, Y: 3.173541, Z: 3.786457
61 - User: 33, Activity: Jogging, Timestamp: 49112252273000, X: 1.838747, Y: 2.764931, Z: -1.757025
62 - User: 33, Activity: Jogging, Timestamp: 49112362289000, X: -1.266692, Y: 19.313654, Z: 6.319841
63 - User: 33, Activity: Jogging, Timestamp: 49112472335000, X: 2.410802, Y: -7.654635, Z: -6.129157
64 - User: 33, Activity: Jogging, Timestamp: 49112572280000, X: -0.612916, Y: 16.358038, Z: 4.944186
65 - User: 33, Activity: Jogging, Timestamp: 49112682296000, X: 0.040861, Y: 17.502148, Z: 2.533385
66 - User: 33, Activity: Jogging, Timestamp: 49112792343000, X: -7.654635, Y: 7.818079, Z: 4.372132
67 - User: 33, Activity: Jogging, Timestamp: 49112902328000, X: -1.266692, Y: 0.721878, Z: 0.803601
68 - User: 33, Activity: Jogging, Timestamp: 49113002273000, X: -5.012288, Y: 19.572440, Z: 5.516241
69 - User: 33, Activity: Jogging, Timestamp: 49113112289000, X: 1.947710, Y: 2.792171, Z: 2.070293
70 - User: 33, Activity: Jogging, Timestamp: 49113222305000, X: -5.053149, Y: 1.648062, Z: 7.627395
71 - User: 33, Activity: Jogging, Timestamp: 49113332290000, X: 9.384419, Y: 13.443283, Z: 1.035146
72 - User: 33, Activity: Jogging, Timestamp: 49113442306000, X: -5.434519, Y: 13.211738, Z: 6.442424
73 - User: 33, Activity: Jogging, Timestamp: 49113560501000, X: -0.612916, Y: 1.879608, Z: 1.416516
74 - User: 33, Activity: Jogging, Timestamp: 49113842239000, X: 4.712640, Y: -6.551387, Z: -6.020194
75 - User: 33, Activity: Jogging, Timestamp: 49113952346000, X: -1.757025, Y: 9.302697, Z: -6.428804
76 - User: 33, Activity: Jogging, Timestamp: 49114052230000, X: -0.912563, Y: 10.501288, Z: -0.272407
77 - User: 33, Activity: Jogging, Timestamp: 49114102218000, X: 2.601486, Y: 19.381754, Z: 4.440233
78 - User: 33, Activity: Jogging, Timestamp: 49114212295000, X: 5.788648, Y: 3.214402, Z: 1.144109
79 - User: 33, Activity: Jogging, Timestamp: 49114312301000, X: -1.988571, Y: 12.448998, Z: -2.724070
80 - User: 33, Activity: Jogging, Timestamp: 49114422317000, X: 1.416516, Y: 16.780268, Z: 8.471856
81 - User: 33, Activity: Jogging, Timestamp: 49114522293000, X: 0.422231, Y: -8.267551, Z: -7.354988
82 - User: 33, Activity: Jogging, Timestamp: 49114632339000, X: -3.568531, Y: 10.950760, Z: -0.803601
83 - User: 33, Activity: Jogging, Timestamp: 49114742355000, X: -4.671779, Y: 11.727119, Z: 0.381370
84 - User: 33, Activity: Jogging, Timestamp: 49114852340000, X: -2.138395, Y: 1.688923, Z: 3.527670
85 - User: 33, Activity: Jogging, Timestamp: 49114962295000, X: -1.334794, Y: 2.492524, Z: -0.340509
86 - User: 33, Activity: Jogging, Timestamp: 49115072311000, X: -2.914754, Y: 19.572440, Z: 7.586533
87 - User: 33, Activity: Jogging, Timestamp: 49115172470000, X: 3.527670, Y: -3.949901, Z: -1.920469
88 - User: 33, Activity: Jogging, Timestamp: 49115272262000, X: -4.058864, Y: 10.038197, Z: 14.287745
89 - User: 33, Activity: Jogging, Timestamp: 49115382339000, X: 7.586533, Y: 13.334320, Z: 3.868179
90 - User: 33, Activity: Jogging, Timestamp: 49115492294000, X: -5.175732, Y: 14.178781, Z: 5.516241
91 - User: 33, Activity: Jogging, Timestamp: 49115602310000, X: 1.184970, Y: 2.111154, Z: 2.220117
92 - User: 33, Activity: Jogging, Timestamp: 49115712295000, X: -3.718355, Y: 19.463476, Z: -0.803601
93 - User: 33, Activity: Jogging, Timestamp: 49115812332000, X: 3.173541, Y: 6.510526, Z: 4.208687
94 - User: 33, Activity: Jogging, Timestamp: 49115912124000, X: -1.729784, Y: -5.625204, Z: -4.331271
95 - User: 33, Activity: Jogging, Timestamp: 49115962234000, X: 0.844462, Y: 12.980191, Z: 11.563675
96 - User: 33, Activity: Jogging, Timestamp: 49116072311000, X: 2.764931, Y: 17.352324, Z: 7.736358
97 - User: 33, Activity: Jogging, Timestamp: 49116122238000, X: 2.342700, Y: 15.894946, Z: 3.677494
98 - User: 33, Activity: Jogging, Timestamp: 49116232315000, X: 4.794363, Y: 3.827318, Z: 0.994285
99 - User: 33, Activity: Jogging, Timestamp: 49116342330000, X: -1.838747, Y: 12.830367, Z: -1.566340
100 - User: 33, Activity: Jogging, Timestamp: 49116452316000, X: 5.366417, Y: 14.410328, Z: 6.742072


======================== Convolution Layer Details ========================
Input Size : 100
Kernel Size: 3
Stride     : 1
Filter Size: 6
Bias       : -0.242898

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.499671
              0 |     1 |      0.024587
              0 |     2 |      0.235424
              1 |     0 |     -0.236694
              1 |     1 |     -0.123776
              1 |     2 |     -0.303714
              2 |     0 |      0.475874
              2 |     1 |      0.012318
              2 |     2 |      0.030449
==========================================================================


Output Layer 1 Details:
Data: 
[0]: 0.129376
[1]: 0.000000
[2]: 0.000000
[3]: 0.000000
[4]: 0.000000
[5]: 6.030567
[6]: 1.365423
[7]: 0.000000
[8]: 0.000000
[9]: 0.855703
[10]: 2.871934
[11]: 0.000000
[12]: 0.000000
[13]: 0.000000
[14]: 0.000000
[15]: 0.658121
[16]: 1.729640
[17]: 6.252910
[18]: 4.184690
[19]: 0.000000
[20]: 0.000000
[21]: 3.273039
[22]: 1.660098
[23]: 0.000000
[24]: 0.000000
[25]: 1.077392
[26]: 3.120336
[27]: 0.000000
[28]: 0.000000
[29]: 0.000000
[30]: 0.000000
[31]: 0.000000
[32]: 0.000000
[33]: 8.575069
[34]: 3.196749
[35]: 0.000000
[36]: 0.000000
[37]: 0.000000
[38]: 0.044344
[39]: 0.000000
[40]: 0.000000
[41]: 0.000000
[42]: 0.000000
[43]: 1.028796
[44]: 0.000000
[45]: 3.659947
[46]: 0.000000
[47]: 0.000000
[48]: 6.093670
[49]: 7.819166
[50]: 4.172822
[51]: 0.000000
[52]: 0.000000
[53]: 0.000000
[54]: 0.000000
[55]: 0.000000
[56]: 0.000000
[57]: 2.626104
[58]: 0.000000
[59]: 0.000000
[60]: 1.675248
[61]: 4.555641
[62]: 3.454102
[63]: 0.000000
[64]: 0.000000
[65]: 0.000000
[66]: 0.000000
[67]: 2.090407
[68]: 6.365080
[69]: 9.943704
[70]: 0.000000
[71]: 0.000000
[72]: 3.368121
[73]: 7.722950
[74]: 0.000000
[75]: 0.000000
[76]: 0.000000
[77]: 2.555835
[78]: 2.718126
[79]: 0.000000
[80]: 0.000000
[81]: 2.007491
[82]: 2.092393
[83]: 0.000000
[84]: 0.000000
[85]: 8.188463
[86]: 1.613902
[87]: 0.000000
[88]: 0.000000
[89]: 0.000000
[90]: 0.000000
[91]: 0.000000
[92]: 0.000000
[93]: 9.707520
[94]: 9.565850
[95]: 0.000000
[96]: 0.000000
[97]: 5.494030


Avarage Pooling Layer 1 Details:
Data: 
[0]: 0.064688
[1]: 0.000000
[2]: 3.015283
[3]: 0.682711
[4]: 0.427851
[5]: 1.435967
[6]: 0.000000
[7]: 0.329061
[8]: 3.991275
[9]: 2.092345
[10]: 1.636519
[11]: 0.830049
[12]: 0.538696
[13]: 1.560168
[14]: 0.000000
[15]: 0.000000
[16]: 4.287535
[17]: 1.598374
[18]: 0.000000
[19]: 0.022172
[20]: 0.000000
[21]: 0.514398
[22]: 1.829973
[23]: 0.000000
[24]: 6.956418
[25]: 2.086411
[26]: 0.000000
[27]: 0.000000
[28]: 1.313052
[29]: 0.000000
[30]: 3.115444
[31]: 1.727051
[32]: 0.000000
[33]: 1.045204
[34]: 8.154392
[35]: 0.000000
[36]: 5.545535
[37]: 0.000000
[38]: 1.277918
[39]: 1.359063
[40]: 1.003746
[41]: 1.046197
[42]: 4.094231
[43]: 0.806951
[44]: 0.000000
[45]: 0.000000
[46]: 4.853760
[47]: 4.782925
[48]: 2.747015


======================== Convolution Layer Details ========================
Input Size : 100
Kernel Size: 3
Stride     : 1
Filter Size: 6
Bias       : 0.307374

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.392913
              0 |     1 |      0.315488
              0 |     2 |      0.400545
              1 |     0 |     -0.047971
              1 |     1 |     -0.254611
              1 |     2 |     -0.252592
              2 |     0 |     -0.311726
              2 |     1 |     -0.176676
              2 |     2 |     -0.396543
==========================================================================


Output Layer 2 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 0.000000
[3]: 0.000000
[4]: 0.000000
[5]: 0.000000
[6]: 0.000000
[7]: 0.000000
[8]: 0.000000
[9]: 0.000000
[10]: 0.000000
[11]: 0.000000
[12]: 0.000000
[13]: 0.000000
[14]: 1.886800
[15]: 0.000000
[16]: 0.000000
[17]: 0.000000
[18]: 0.000000
[19]: 0.000000
[20]: 0.000000
[21]: 0.000000
[22]: 1.304817
[23]: 0.000000
[24]: 0.000000
[25]: 0.000000
[26]: 0.119775
[27]: 0.000000
[28]: 0.000000
[29]: 0.000000
[30]: 2.557908
[31]: 0.000000
[32]: 0.000000
[33]: 0.000000
[34]: 0.888557
[35]: 0.000000
[36]: 0.000000
[37]: 0.000000
[38]: 0.000000
[39]: 0.000000
[40]: 0.000000
[41]: 0.252990
[42]: 3.162936
[43]: 0.000000
[44]: 5.168129
[45]: 0.000000
[46]: 2.101518
[47]: 0.000000
[48]: 0.000000
[49]: 0.000000
[50]: 0.000000
[51]: 0.000000
[52]: 0.000000
[53]: 0.000000
[54]: 0.000000
[55]: 0.000000
[56]: 0.000000
[57]: 0.000000
[58]: 0.000000
[59]: 0.000000
[60]: 0.000000
[61]: 0.000000
[62]: 0.000000
[63]: 0.000000
[64]: 0.000000
[65]: 0.834488
[66]: 2.447305
[67]: 0.000000
[68]: 7.606830
[69]: 7.763778
[70]: 3.680303
[71]: 0.000000
[72]: 0.000000
[73]: 3.658738
[74]: 1.066603
[75]: 0.000000
[76]: 0.000000
[77]: 4.612023
[78]: 7.401856
[79]: 0.000000
[80]: 0.000000
[81]: 3.110303
[82]: 9.271683
[83]: 0.000000
[84]: 0.000000
[85]: 0.000000
[86]: 0.000000
[87]: 0.000000
[88]: 0.000000
[89]: 3.596608
[90]: 7.302988
[91]: 0.000000
[92]: 0.000000
[93]: 1.302861
[94]: 1.347265
[95]: 0.000000
[96]: 0.000000
[97]: 0.000000


Avarage Pooling Layer 2 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 0.000000
[3]: 0.000000
[4]: 0.000000
[5]: 0.000000
[6]: 0.000000
[7]: 0.943400
[8]: 0.000000
[9]: 0.000000
[10]: 0.000000
[11]: 0.652408
[12]: 0.000000
[13]: 0.059888
[14]: 0.000000
[15]: 1.278954
[16]: 0.000000
[17]: 0.444278
[18]: 0.000000
[19]: 0.000000
[20]: 0.126495
[21]: 1.581468
[22]: 2.584065
[23]: 1.050759
[24]: 0.000000
[25]: 0.000000
[26]: 0.000000
[27]: 0.000000
[28]: 0.000000
[29]: 0.000000
[30]: 0.000000
[31]: 0.000000
[32]: 0.417244
[33]: 1.223652
[34]: 7.685304
[35]: 1.840152
[36]: 1.829369
[37]: 0.533302
[38]: 2.306011
[39]: 3.700928
[40]: 1.555152
[41]: 4.635841
[42]: 0.000000
[43]: 0.000000
[44]: 1.798304
[45]: 3.651494
[46]: 0.651431
[47]: 0.673633
[48]: 0.000000


======================== Convolution Layer Details ========================
Input Size : 100
Kernel Size: 3
Stride     : 1
Filter Size: 6
Bias       : -0.049995

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |      0.034411
              0 |     1 |      0.344454
              0 |     2 |      0.237019
              1 |     0 |     -0.421667
              1 |     1 |      0.039009
              1 |     2 |     -0.368991
              2 |     0 |      0.362525
              2 |     1 |     -0.035404
              2 |     2 |     -0.028027
==========================================================================


Output Layer 3 Details:
Data: 
[0]: 3.782077
[1]: 0.000000
[2]: 0.000000
[3]: 0.000000
[4]: 0.000000
[5]: 1.956333
[6]: 1.340011
[7]: 0.000000
[8]: 0.000000
[9]: 0.000000
[10]: 1.685746
[11]: 0.000000
[12]: 0.000000
[13]: 0.000000
[14]: 0.000000
[15]: 0.648859
[16]: 0.918692
[17]: 4.376676
[18]: 5.004471
[19]: 0.000000
[20]: 0.000000
[21]: 0.522307
[22]: 0.523571
[23]: 0.000000
[24]: 0.000000
[25]: 0.000000
[26]: 1.920763
[27]: 0.000000
[28]: 2.306351
[29]: 0.000000
[30]: 0.000000
[31]: 0.000000
[32]: 0.000000
[33]: 6.433291
[34]: 3.228441
[35]: 0.000000
[36]: 3.390779
[37]: 0.000000
[38]: 0.000000
[39]: 0.000000
[40]: 0.000000
[41]: 0.000000
[42]: 0.000000
[43]: 1.002311
[44]: 0.000000
[45]: 3.968606
[46]: 0.000000
[47]: 0.000000
[48]: 7.048688
[49]: 2.968210
[50]: 4.159146
[51]: 0.000000
[52]: 0.000000
[53]: 0.000000
[54]: 0.000000
[55]: 0.000000
[56]: 0.000000
[57]: 1.869542
[58]: 0.000000
[59]: 0.000000
[60]: 2.005808
[61]: 0.983926
[62]: 2.736636
[63]: 0.000000
[64]: 0.000000
[65]: 0.000000
[66]: 0.000000
[67]: 1.589017
[68]: 6.439346
[69]: 10.447319
[70]: 3.878571
[71]: 0.000000
[72]: 4.737210
[73]: 4.382861
[74]: 7.203951
[75]: 0.000000
[76]: 0.000000
[77]: 0.000000
[78]: 7.966239
[79]: 0.215190
[80]: 0.000000
[81]: 1.535130
[82]: 5.198898
[83]: 1.713307
[84]: 0.000000
[85]: 5.989115
[86]: 1.260716
[87]: 0.000000
[88]: 0.000000
[89]: 0.000000
[90]: 0.780528
[91]: 3.142669
[92]: 1.365772
[93]: 7.742988
[94]: 12.919055
[95]: 0.000000
[96]: 0.000000
[97]: 1.142439


Avarage Pooling Layer 3 Details:
Data: 
[0]: 1.891038
[1]: 0.000000
[2]: 0.978166
[3]: 0.670005
[4]: 0.000000
[5]: 0.842873
[6]: 0.000000
[7]: 0.324430
[8]: 2.647684
[9]: 2.502235
[10]: 0.261153
[11]: 0.261786
[12]: 0.000000
[13]: 0.960381
[14]: 1.153175
[15]: 0.000000
[16]: 3.216646
[17]: 1.614220
[18]: 1.695390
[19]: 0.000000
[20]: 0.000000
[21]: 0.501155
[22]: 1.984303
[23]: 0.000000
[24]: 5.008449
[25]: 2.079573
[26]: 0.000000
[27]: 0.000000
[28]: 0.934771
[29]: 0.000000
[30]: 1.494867
[31]: 1.368318
[32]: 0.000000
[33]: 0.794508
[34]: 8.443333
[35]: 1.939285
[36]: 4.560036
[37]: 3.601975
[38]: 0.000000
[39]: 4.090714
[40]: 0.767565
[41]: 3.456102
[42]: 2.994557
[43]: 0.630358
[44]: 0.000000
[45]: 1.961599
[46]: 4.554380
[47]: 6.459528
[48]: 0.571219


======================== Convolution Layer Details ========================
Input Size : 100
Kernel Size: 3
Stride     : 1
Filter Size: 6
Bias       : -0.155776

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.266525
              0 |     1 |     -0.487682
              0 |     2 |     -0.476974
              1 |     0 |      0.493510
              1 |     1 |      0.415439
              1 |     2 |      0.285837
              2 |     0 |      0.070820
              2 |     1 |      0.269240
              2 |     2 |      0.123570
==========================================================================


Output Layer 4 Details:
Data: 
[0]: 4.297773
[1]: 2.922473
[2]: 1.500461
[3]: 7.112515
[4]: 12.072006
[5]: 7.304991
[6]: 0.000000
[7]: 6.053775
[8]: 12.156696
[9]: 13.026003
[10]: 1.678007
[11]: 2.875382
[12]: 4.971105
[13]: 6.883770
[14]: 3.256443
[15]: 0.844308
[16]: 1.134185
[17]: 0.000000
[18]: 0.000000
[19]: 4.198501
[20]: 10.155236
[21]: 10.318524
[22]: 1.974437
[23]: 2.761953
[24]: 10.516933
[25]: 11.849225
[26]: 1.397673
[27]: 0.030856
[28]: 2.534502
[29]: 8.151444
[30]: 1.754365
[31]: 0.844475
[32]: 6.382949
[33]: 3.327340
[34]: 0.000000
[35]: 3.129077
[36]: 6.734964
[37]: 11.848152
[38]: 1.572454
[39]: 1.212655
[40]: 2.827485
[41]: 3.648250
[42]: 0.000428
[43]: 0.000000
[44]: 0.000000
[45]: 0.000000
[46]: 0.000000
[47]: 3.050772
[48]: 3.649683
[49]: 3.410370
[50]: 0.000000
[51]: 9.471996
[52]: 14.250580
[53]: 13.274255
[54]: 5.866413
[55]: 3.910321
[56]: 6.961247
[57]: 2.723211
[58]: 1.167668
[59]: 4.197855
[60]: 7.180614
[61]: 6.839382
[62]: 0.550055
[63]: 3.943565
[64]: 6.987176
[65]: 7.320993
[66]: 3.535752
[67]: 0.000000
[68]: 0.000000
[69]: 0.000000
[70]: 0.000000
[71]: 3.131307
[72]: 4.255595
[73]: 0.000000
[74]: 0.000000
[75]: 2.717171
[76]: 9.505704
[77]: 0.000000
[78]: 0.000000
[79]: 0.000000
[80]: 2.326469
[81]: 0.000000
[82]: 0.000000
[83]: 0.000000
[84]: 2.678215
[85]: 4.368675
[86]: 3.180575
[87]: 7.171978
[88]: 8.586190
[89]: 5.985458
[90]: 0.000000
[91]: 0.000000
[92]: 0.099971
[93]: 0.000000
[94]: 0.000000
[95]: 0.000000
[96]: 15.969411
[97]: 12.246780


Avarage Pooling Layer 4 Details:
Data: 
[0]: 3.610123
[1]: 4.306488
[2]: 9.688499
[3]: 3.026887
[4]: 12.591350
[5]: 2.276694
[6]: 5.927437
[7]: 2.050376
[8]: 0.567093
[9]: 2.099251
[10]: 10.236880
[11]: 2.368195
[12]: 11.183079
[13]: 0.714265
[14]: 5.342973
[15]: 1.299420
[16]: 4.855144
[17]: 1.564538
[18]: 9.291558
[19]: 1.392554
[20]: 3.237867
[21]: 0.000214
[22]: 0.000000
[23]: 1.525386
[24]: 3.530027
[25]: 4.735998
[26]: 13.762418
[27]: 4.888367
[28]: 4.842229
[29]: 2.682762
[30]: 7.009998
[31]: 2.246810
[32]: 7.154085
[33]: 1.767876
[34]: 0.000000
[35]: 1.565654
[36]: 2.127797
[37]: 1.358585
[38]: 4.752852
[39]: 0.000000
[40]: 1.163235
[41]: 0.000000
[42]: 3.523445
[43]: 5.176276
[44]: 7.285824
[45]: 0.000000
[46]: 0.049986
[47]: 0.000000
[48]: 14.108095


======================== Convolution Layer Details ========================
Input Size : 100
Kernel Size: 3
Stride     : 1
Filter Size: 6
Bias       : -0.170721

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.124367
              0 |     1 |     -0.232888
              0 |     2 |     -0.148263
              1 |     0 |      0.140945
              1 |     1 |     -0.136220
              1 |     2 |     -0.447193
              2 |     0 |      0.028658
              2 |     1 |     -0.342301
              2 |     2 |     -0.046181
==========================================================================


Output Layer 5 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 0.000000
[3]: 0.000000
[4]: 0.000000
[5]: 0.869322
[6]: 0.233230
[7]: 0.000000
[8]: 0.000000
[9]: 0.000000
[10]: 0.928324
[11]: 0.000000
[12]: 0.000000
[13]: 2.711550
[14]: 0.071354
[15]: 0.478219
[16]: 0.000000
[17]: 0.000000
[18]: 0.000000
[19]: 0.000000
[20]: 0.000000
[21]: 0.000000
[22]: 1.450554
[23]: 0.000000
[24]: 0.000000
[25]: 0.000000
[26]: 4.697101
[27]: 0.000000
[28]: 0.000000
[29]: 0.213825
[30]: 0.552542
[31]: 0.987015
[32]: 0.000000
[33]: 0.000000
[34]: 3.740951
[35]: 0.000000
[36]: 0.000000
[37]: 1.361704
[38]: 0.000000
[39]: 0.000000
[40]: 0.000000
[41]: 0.255923
[42]: 1.364711
[43]: 3.200855
[44]: 0.000000
[45]: 2.438706
[46]: 2.024936
[47]: 0.000000
[48]: 0.000000
[49]: 0.000000
[50]: 0.000000
[51]: 0.000000
[52]: 0.000000
[53]: 0.291599
[54]: 0.000000
[55]: 0.000000
[56]: 0.000000
[57]: 0.589615
[58]: 0.735877
[59]: 0.000000
[60]: 0.000000
[61]: 0.000000
[62]: 0.000000
[63]: 0.000000
[64]: 0.000000
[65]: 3.785065
[66]: 1.645615
[67]: 1.233971
[68]: 1.123208
[69]: 1.200497
[70]: 0.000000
[71]: 0.000000
[72]: 0.000000
[73]: 0.000000
[74]: 0.000000
[75]: 0.000000
[76]: 0.000000
[77]: 0.000000
[78]: 0.000000
[79]: 0.000000
[80]: 0.000000
[81]: 0.000000
[82]: 0.000000
[83]: 0.000000
[84]: 0.000000
[85]: 0.000000
[86]: 3.034974
[87]: 0.000000
[88]: 0.000000
[89]: 1.767450
[90]: 0.000000
[91]: 0.000000
[92]: 0.000000
[93]: 0.000000
[94]: 0.000000
[95]: 0.000000
[96]: 0.000000
[97]: 0.000000


Avarage Pooling Layer 5 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 0.434661
[3]: 0.116615
[4]: 0.000000
[5]: 0.464162
[6]: 1.355775
[7]: 0.274786
[8]: 0.000000
[9]: 0.000000
[10]: 0.000000
[11]: 0.725277
[12]: 0.000000
[13]: 2.348551
[14]: 0.106912
[15]: 0.769778
[16]: 0.000000
[17]: 1.870476
[18]: 0.680852
[19]: 0.000000
[20]: 0.127961
[21]: 2.282783
[22]: 1.219353
[23]: 1.012468
[24]: 0.000000
[25]: 0.000000
[26]: 0.145800
[27]: 0.000000
[28]: 0.294808
[29]: 0.367938
[30]: 0.000000
[31]: 0.000000
[32]: 1.892533
[33]: 1.439793
[34]: 1.161853
[35]: 0.000000
[36]: 0.000000
[37]: 0.000000
[38]: 0.000000
[39]: 0.000000
[40]: 0.000000
[41]: 0.000000
[42]: 0.000000
[43]: 1.517487
[44]: 0.883725
[45]: 0.000000
[46]: 0.000000
[47]: 0.000000
[48]: 0.000000


======================== Convolution Layer Details ========================
Input Size : 100
Kernel Size: 3
Stride     : 1
Filter Size: 6
Bias       : 0.043702

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.307219
              0 |     1 |     -0.435266
              0 |     2 |      0.486526
              1 |     0 |      0.046087
              1 |     1 |     -0.410871
              1 |     2 |      0.493302
              2 |     0 |     -0.066270
              2 |     1 |      0.201564
              2 |     2 |     -0.313260
==========================================================================


Output Layer 6 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 2.549058
[3]: 0.000000
[4]: 0.000000
[5]: 0.000000
[6]: 0.000000
[7]: 5.387916
[8]: 0.000000
[9]: 0.303668
[10]: 0.000000
[11]: 7.561808
[12]: 0.014307
[13]: 0.000000
[14]: 1.677836
[15]: 0.000000
[16]: 0.000000
[17]: 3.053692
[18]: 0.000000
[19]: 1.038750
[20]: 0.000000
[21]: 0.000000
[22]: 2.231652
[23]: 1.856081
[24]: 0.000000
[25]: 0.000000
[26]: 0.000000
[27]: 8.899471
[28]: 0.000000
[29]: 0.000000
[30]: 3.210021
[31]: 0.000000
[32]: 3.970554
[33]: 0.000000
[34]: 0.000000
[35]: 11.539917
[36]: 0.000000
[37]: 0.044125
[38]: 1.259150
[39]: 2.872798
[40]: 0.000000
[41]: 0.000000
[42]: 1.193834
[43]: 0.000000
[44]: 5.377685
[45]: 0.000000
[46]: 0.000000
[47]: 1.476059
[48]: 0.000000
[49]: 4.239659
[50]: 0.010511
[51]: 6.862187
[52]: 0.000000
[53]: 0.000000
[54]: 3.832232
[55]: 0.000000
[56]: 2.780386
[57]: 0.000000
[58]: 0.000000
[59]: 1.238704
[60]: 0.000000
[61]: 2.024392
[62]: 1.727870
[63]: 6.678487
[64]: 1.446460
[65]: 0.000000
[66]: 0.000000
[67]: 0.000000
[68]: 4.654749
[69]: 4.619929
[70]: 0.000000
[71]: 0.000000
[72]: 0.000000
[73]: 7.080280
[74]: 0.000000
[75]: 0.702207
[76]: 0.000000
[77]: 9.800489
[78]: 0.000000
[79]: 0.000000
[80]: 0.000000
[81]: 5.005634
[82]: 0.000000
[83]: 0.000000
[84]: 0.000000
[85]: 0.000000
[86]: 0.000000
[87]: 15.635166
[88]: 0.000000
[89]: 2.964831
[90]: 0.000000
[91]: 0.000000
[92]: 0.000000
[93]: 10.807221
[94]: 0.000000
[95]: 0.000000
[96]: 0.000000
[97]: 4.419357


Avarage Pooling Layer 6 Details:
Data: 
[0]: 0.000000
[1]: 1.274529
[2]: 0.000000
[3]: 2.693958
[4]: 0.151834
[5]: 3.780904
[6]: 0.007154
[7]: 0.838918
[8]: 1.526846
[9]: 0.519375
[10]: 0.000000
[11]: 2.043866
[12]: 0.000000
[13]: 4.449736
[14]: 0.000000
[15]: 1.605011
[16]: 1.985277
[17]: 5.769959
[18]: 0.022062
[19]: 2.065974
[20]: 0.000000
[21]: 0.596917
[22]: 2.688843
[23]: 0.738030
[24]: 2.119830
[25]: 3.436349
[26]: 0.000000
[27]: 1.916116
[28]: 1.390193
[29]: 0.619352
[30]: 1.012196
[31]: 4.203179
[32]: 0.723230
[33]: 0.000000
[34]: 4.637339
[35]: 0.000000
[36]: 3.540140
[37]: 0.351104
[38]: 4.900245
[39]: 0.000000
[40]: 2.502817
[41]: 0.000000
[42]: 0.000000
[43]: 7.817583
[44]: 1.482415
[45]: 0.000000
[46]: 5.403610
[47]: 0.000000
[48]: 2.209679


======================== Convolution Layer Details ========================
Input Size : 49
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : 0.483599

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |      0.495430
              0 |     1 |     -0.310038
              0 |     2 |      0.184262
              1 |     0 |     -0.100616
              1 |     1 |     -0.061031
              1 |     2 |      0.247021
              2 |     0 |     -0.321931
              2 |     1 |      0.310782
              2 |     2 |      0.306098
              3 |     0 |     -0.402539
              3 |     1 |     -0.470302
              3 |     2 |     -0.366030
              4 |     0 |      0.137436
              4 |     1 |     -0.119667
              4 |     2 |     -0.250609
              5 |     0 |      0.006725
              5 |     1 |      0.021158
              5 |     2 |     -0.396473
==========================================================================


Output Layer 1 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 0.000000
[3]: 0.000000
[4]: 0.000000
[5]: 0.000000
[6]: 0.000000
[7]: 0.000000
[8]: 0.000000
[9]: 0.000000
[10]: 0.000000
[11]: 0.000000
[12]: 0.000000
[13]: 0.000000
[14]: 0.000000
[15]: 0.000000
[16]: 0.000000
[17]: 0.000000
[18]: 0.000000
[19]: 0.000000
[20]: 0.000000
[21]: 0.000000
[22]: 0.472350
[23]: 0.000000
[24]: 0.000000
[25]: 0.000000
[26]: 0.000000
[27]: 0.000000
[28]: 0.000000
[29]: 0.000000
[30]: 0.000000
[31]: 0.000000
[32]: 0.526958
[33]: 0.169755
[34]: 1.664154
[35]: 0.000000
[36]: 0.000000
[37]: 0.000000
[38]: 0.000000
[39]: 1.201766
[40]: 0.974049
[41]: 0.000000
[42]: 0.000000
[43]: 0.000000
[44]: 0.000000
[45]: 2.471296
[46]: 0.000000


Avarage Pooling Layer 1 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 0.000000
[3]: 0.000000
[4]: 0.000000
[5]: 0.000000
[6]: 0.000000
[7]: 0.000000
[8]: 0.000000
[9]: 0.000000
[10]: 0.000000
[11]: 0.236175
[12]: 0.000000
[13]: 0.000000
[14]: 0.000000
[15]: 0.000000
[16]: 0.348356
[17]: 0.832077
[18]: 0.000000
[19]: 0.600883
[20]: 0.487024
[21]: 0.000000
[22]: 1.235648


======================== Convolution Layer Details ========================
Input Size : 49
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : -0.156553

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.151409
              0 |     1 |      0.268327
              0 |     2 |     -0.234654
              1 |     0 |      0.166443
              1 |     1 |      0.415123
              1 |     2 |     -0.033620
              2 |     0 |     -0.059176
              2 |     1 |      0.421430
              2 |     2 |     -0.032696
              3 |     0 |      0.477231
              3 |     1 |     -0.179967
              3 |     2 |      0.294185
              4 |     0 |      0.365517
              4 |     1 |      0.242640
              4 |     2 |      0.057495
              5 |     0 |      0.326770
              5 |     1 |      0.031226
              5 |     2 |     -0.192608
==========================================================================


Output Layer 2 Details:
Data: 
[0]: 2.845052
[1]: 2.094464
[2]: 7.719317
[3]: 0.000000
[4]: 8.219073
[5]: 1.668118
[6]: 2.360225
[7]: 3.361661
[8]: 3.725364
[9]: 0.000000
[10]: 8.046533
[11]: 0.000000
[12]: 8.067542
[13]: 1.838462
[14]: 2.832754
[15]: 2.190244
[16]: 6.328635
[17]: 2.110398
[18]: 5.208894
[19]: 0.506690
[20]: 2.005759
[21]: 4.137967
[22]: 0.467839
[23]: 4.939559
[24]: 5.619425
[25]: 1.415166
[26]: 6.479700
[27]: 3.483315
[28]: 3.175373
[29]: 1.098008
[30]: 5.786489
[31]: 1.604687
[32]: 2.135276
[33]: 10.910488
[34]: 1.059962
[35]: 4.875267
[36]: 2.793529
[37]: 0.502894
[38]: 7.075432
[39]: 0.604432
[40]: 4.917446
[41]: 1.872951
[42]: 2.738969
[43]: 4.772590
[44]: 4.433864
[45]: 2.630853
[46]: 8.083828


Avarage Pooling Layer 2 Details:
Data: 
[0]: 2.469758
[1]: 3.859659
[2]: 4.943596
[3]: 2.860943
[4]: 1.862682
[5]: 4.023267
[6]: 4.953002
[7]: 2.511499
[8]: 4.219517
[9]: 2.857792
[10]: 3.071863
[11]: 2.703699
[12]: 3.517296
[13]: 4.981507
[14]: 2.136690
[15]: 3.695588
[16]: 6.522882
[17]: 2.967615
[18]: 1.648212
[19]: 3.839932
[20]: 3.395199
[21]: 3.755780
[22]: 3.532359


======================== Convolution Layer Details ========================
Input Size : 49
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : 0.210236

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.188675
              0 |     1 |     -0.053426
              0 |     2 |      0.066767
              1 |     0 |      0.152529
              1 |     1 |     -0.437080
              1 |     2 |     -0.010236
              2 |     0 |     -0.043761
              2 |     1 |     -0.490498
              2 |     2 |      0.201041
              3 |     0 |     -0.111742
              3 |     1 |     -0.053107
              3 |     2 |      0.436165
              4 |     0 |     -0.374848
              4 |     1 |     -0.071709
              4 |     2 |     -0.207478
              5 |     0 |     -0.089026
              5 |     1 |     -0.256330
              5 |     2 |     -0.134336
==========================================================================


Output Layer 3 Details:
Data: 
[0]: 3.690045
[1]: 0.000000
[2]: 2.628289
[3]: 0.000000
[4]: 0.000000
[5]: 0.000000
[6]: 0.000000
[7]: 0.000000
[8]: 2.185015
[9]: 0.000000
[10]: 2.500194
[11]: 0.000000
[12]: 0.000000
[13]: 0.000000
[14]: 1.211926
[15]: 0.000000
[16]: 0.022945
[17]: 0.000000
[18]: 0.000000
[19]: 0.000000
[20]: 0.000000
[21]: 0.000000
[22]: 1.400037
[23]: 0.000000
[24]: 1.803977
[25]: 0.023843
[26]: 0.006663
[27]: 0.000000
[28]: 2.248701
[29]: 0.000000
[30]: 0.000000
[31]: 0.000000
[32]: 0.000000
[33]: 0.000000
[34]: 0.000000
[35]: 0.000000
[36]: 0.000000
[37]: 0.000000
[38]: 0.000000
[39]: 0.000000
[40]: 0.000000
[41]: 0.000000
[42]: 0.000000
[43]: 0.000000
[44]: 0.000000
[45]: 0.000000
[46]: 1.144383


Avarage Pooling Layer 3 Details:
Data: 
[0]: 1.845022
[1]: 1.314145
[2]: 0.000000
[3]: 0.000000
[4]: 1.092508
[5]: 1.250097
[6]: 0.000000
[7]: 0.605963
[8]: 0.011473
[9]: 0.000000
[10]: 0.000000
[11]: 0.700019
[12]: 0.913910
[13]: 0.003331
[14]: 1.124350
[15]: 0.000000
[16]: 0.000000
[17]: 0.000000
[18]: 0.000000
[19]: 0.000000
[20]: 0.000000
[21]: 0.000000
[22]: 0.000000


======================== Convolution Layer Details ========================
Input Size : 49
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : -0.215536

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |      0.435564
              0 |     1 |     -0.482181
              0 |     2 |     -0.022055
              1 |     0 |      0.321594
              1 |     1 |      0.032702
              1 |     2 |     -0.374017
              2 |     0 |     -0.099683
              2 |     1 |     -0.371196
              2 |     2 |      0.312423
              3 |     0 |     -0.108313
              3 |     1 |     -0.423746
              3 |     2 |      0.097628
              4 |     0 |     -0.163339
              4 |     1 |     -0.246392
              4 |     2 |     -0.113535
              5 |     0 |     -0.185927
              5 |     1 |      0.116541
              5 |     2 |     -0.295782
==========================================================================


Output Layer 4 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 0.000000
[3]: 0.000000
[4]: 0.000000
[5]: 0.000000
[6]: 0.000000
[7]: 0.000000
[8]: 0.000000
[9]: 0.000000
[10]: 0.000000
[11]: 0.000000
[12]: 0.000000
[13]: 0.000000
[14]: 0.000000
[15]: 0.000000
[16]: 0.000000
[17]: 0.000000
[18]: 0.000000
[19]: 0.000000
[20]: 0.000000
[21]: 0.000000
[22]: 0.869139
[23]: 0.000000
[24]: 0.000000
[25]: 0.000000
[26]: 0.000000
[27]: 0.000000
[28]: 0.000000
[29]: 0.000000
[30]: 0.000000
[31]: 0.000000
[32]: 0.000000
[33]: 0.000000
[34]: 2.369770
[35]: 0.000000
[36]: 0.000000
[37]: 0.000000
[38]: 0.000000
[39]: 0.000000
[40]: 0.000000
[41]: 0.000000
[42]: 0.000000
[43]: 0.000000
[44]: 0.000000
[45]: 0.000000
[46]: 0.000000


Avarage Pooling Layer 4 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 0.000000
[3]: 0.000000
[4]: 0.000000
[5]: 0.000000
[6]: 0.000000
[7]: 0.000000
[8]: 0.000000
[9]: 0.000000
[10]: 0.000000
[11]: 0.434569
[12]: 0.000000
[13]: 0.000000
[14]: 0.000000
[15]: 0.000000
[16]: 0.000000
[17]: 1.184885
[18]: 0.000000
[19]: 0.000000
[20]: 0.000000
[21]: 0.000000
[22]: 0.000000


======================== Convolution Layer Details ========================
Input Size : 49
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : -0.091514

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |      0.489123
              0 |     1 |     -0.303614
              0 |     2 |      0.161838
              1 |     0 |      0.014178
              1 |     1 |      0.284562
              1 |     2 |     -0.372829
              2 |     0 |     -0.141862
              2 |     1 |     -0.277634
              2 |     2 |     -0.201186
              3 |     0 |     -0.331799
              3 |     1 |      0.456430
              3 |     2 |      0.225745
              4 |     0 |      0.089309
              4 |     1 |      0.017611
              4 |     2 |     -0.010718
              5 |     0 |     -0.134004
              5 |     1 |     -0.206706
              5 |     2 |     -0.110198
==========================================================================


Output Layer 5 Details:
Data: 
[0]: 2.649846
[1]: 1.912411
[2]: 1.397156
[3]: 4.533402
[4]: 0.000000
[5]: 2.002259
[6]: 0.000000
[7]: 0.000000
[8]: 3.136405
[9]: 4.053883
[10]: 0.419179
[11]: 3.915131
[12]: 0.000000
[13]: 1.664484
[14]: 0.000000
[15]: 0.000000
[16]: 0.166366
[17]: 3.210297
[18]: 0.000000
[19]: 0.000000
[20]: 0.000000
[21]: 0.000000
[22]: 1.849273
[23]: 0.000000
[24]: 4.490942
[25]: 5.778627
[26]: 0.000000
[27]: 0.000000
[28]: 1.428843
[29]: 0.645885
[30]: 0.000000
[31]: 2.455043
[32]: 0.000000
[33]: 0.000000
[34]: 2.378584
[35]: 0.000000
[36]: 0.398835
[37]: 0.000000
[38]: 0.000000
[39]: 0.000000
[40]: 0.488803
[41]: 0.000000
[42]: 1.472007
[43]: 0.000000
[44]: 0.000000
[45]: 0.000000
[46]: 1.122140


Avarage Pooling Layer 5 Details:
Data: 
[0]: 2.281129
[1]: 2.965279
[2]: 1.001129
[3]: 0.000000
[4]: 3.595144
[5]: 2.167155
[6]: 0.832242
[7]: 0.000000
[8]: 1.688331
[9]: 0.000000
[10]: 0.000000
[11]: 0.924637
[12]: 5.134784
[13]: 0.000000
[14]: 1.037364
[15]: 1.227521
[16]: 0.000000
[17]: 1.189292
[18]: 0.199417
[19]: 0.000000
[20]: 0.244401
[21]: 0.736004
[22]: 0.000000


======================== Convolution Layer Details ========================
Input Size : 49
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : 0.312339

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.070695
              0 |     1 |     -0.178089
              0 |     2 |     -0.147343
              1 |     0 |     -0.391371
              1 |     1 |      0.229066
              1 |     2 |     -0.090646
              2 |     0 |     -0.489864
              2 |     1 |     -0.148805
              2 |     2 |      0.036514
              3 |     0 |     -0.308242
              3 |     1 |      0.370287
              3 |     2 |      0.412891
              4 |     0 |      0.464883
              4 |     1 |      0.294445
              4 |     2 |     -0.266853
              5 |     0 |      0.009918
              5 |     1 |     -0.302768
              5 |     2 |      0.371292
==========================================================================


Output Layer 6 Details:
Data: 
[0]: 2.953113
[1]: 4.173276
[2]: 2.146082
[3]: 5.663209
[4]: 0.000000
[5]: 2.903910
[6]: 0.120606
[7]: 0.000000
[8]: 2.443741
[9]: 3.128269
[10]: 1.885613
[11]: 4.662670
[12]: 0.000000
[13]: 3.273330
[14]: 0.892525
[15]: 1.811880
[16]: 0.000000
[17]: 4.400080
[18]: 0.000000
[19]: 0.579317
[20]: 0.253400
[21]: 0.532717
[22]: 1.075809
[23]: 1.589933
[24]: 1.975732
[25]: 5.589156
[26]: 0.000000
[27]: 1.149980
[28]: 2.199803
[29]: 3.458360
[30]: 0.000000
[31]: 2.061813
[32]: 0.000000
[33]: 0.000000
[34]: 0.000000
[35]: 0.000000
[36]: 0.000000
[37]: 0.000000
[38]: 0.000000
[39]: 0.000000
[40]: 0.245200
[41]: 1.399988
[42]: 0.388821
[43]: 1.795733
[44]: 0.000000
[45]: 0.000000
[46]: 2.124370


Avarage Pooling Layer 6 Details:
Data: 
[0]: 3.563195
[1]: 3.904646
[2]: 1.451955
[3]: 0.060303
[4]: 2.786005
[5]: 3.274141
[6]: 1.636665
[7]: 1.352203
[8]: 2.200040
[9]: 0.289658
[10]: 0.393059
[11]: 1.332871
[12]: 3.782444
[13]: 0.574990
[14]: 2.829082
[15]: 1.030906
[16]: 0.000000
[17]: 0.000000
[18]: 0.000000
[19]: 0.000000
[20]: 0.822594
[21]: 1.092277
[22]: 0.000000


======================== Convolution Layer Details ========================
Input Size : 49
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : -0.283463

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |      0.484670
              0 |     1 |     -0.155761
              0 |     2 |      0.128409
              1 |     0 |      0.174593
              1 |     1 |      0.392433
              1 |     2 |     -0.377094
              2 |     0 |      0.180014
              2 |     1 |      0.496607
              2 |     2 |      0.475673
              3 |     0 |     -0.369675
              3 |     1 |     -0.130866
              3 |     2 |     -0.459568
              4 |     0 |      0.042879
              4 |     1 |     -0.325281
              4 |     2 |      0.005275
              5 |     0 |     -0.343887
              5 |     1 |      0.293018
              5 |     2 |     -0.249853
==========================================================================


Output Layer 7 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 0.000000
[3]: 0.000000
[4]: 0.000000
[5]: 0.000000
[6]: 0.000000
[7]: 0.495213
[8]: 0.000000
[9]: 0.000000
[10]: 0.000000
[11]: 0.000000
[12]: 0.000000
[13]: 0.000000
[14]: 0.000000
[15]: 0.000000
[16]: 0.000000
[17]: 0.000000
[18]: 0.000000
[19]: 0.000000
[20]: 0.000000
[21]: 1.054101
[22]: 1.762829
[23]: 0.000000
[24]: 0.000000
[25]: 0.000000
[26]: 0.000000
[27]: 0.000000
[28]: 0.000000
[29]: 0.000000
[30]: 0.000000
[31]: 0.000000
[32]: 0.000000
[33]: 6.416755
[34]: 6.794811
[35]: 3.485843
[36]: 0.000000
[37]: 2.079618
[38]: 0.000000
[39]: 3.204214
[40]: 3.025539
[41]: 0.000000
[42]: 0.000000
[43]: 0.000000
[44]: 0.443272
[45]: 7.478117
[46]: 0.000000


Avarage Pooling Layer 7 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 0.000000
[3]: 0.247607
[4]: 0.000000
[5]: 0.000000
[6]: 0.000000
[7]: 0.000000
[8]: 0.000000
[9]: 0.000000
[10]: 0.527050
[11]: 0.881415
[12]: 0.000000
[13]: 0.000000
[14]: 0.000000
[15]: 0.000000
[16]: 3.208377
[17]: 5.140327
[18]: 1.039809
[19]: 1.602107
[20]: 1.512770
[21]: 0.000000
[22]: 3.960694


======================== Convolution Layer Details ========================
Input Size : 49
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : 0.315760

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.162418
              0 |     1 |      0.245428
              0 |     2 |     -0.085711
              1 |     0 |      0.457433
              1 |     1 |      0.075025
              1 |     2 |     -0.048127
              2 |     0 |      0.137290
              2 |     1 |      0.437198
              2 |     2 |     -0.007321
              3 |     0 |     -0.039889
              3 |     1 |     -0.414574
              3 |     2 |      0.253326
              4 |     0 |     -0.348719
              4 |     1 |      0.071881
              4 |     2 |      0.106256
              5 |     0 |     -0.155775
              5 |     1 |     -0.110804
              5 |     2 |     -0.277901
==========================================================================


Output Layer 8 Details:
Data: 
[0]: 0.729221
[1]: 0.000000
[2]: 1.448624
[3]: 0.000000
[4]: 0.755504
[5]: 0.000000
[6]: 0.000000
[7]: 2.352763
[8]: 2.901282
[9]: 0.000000
[10]: 1.675259
[11]: 0.000000
[12]: 1.325550
[13]: 0.000000
[14]: 0.000000
[15]: 0.000000
[16]: 1.943530
[17]: 0.000000
[18]: 0.000000
[19]: 0.000000
[20]: 0.000000
[21]: 1.673967
[22]: 0.000000
[23]: 2.516912
[24]: 1.981439
[25]: 0.000000
[26]: 0.000000
[27]: 0.000000
[28]: 0.000000
[29]: 0.000000
[30]: 0.994930
[31]: 0.000000
[32]: 0.000000
[33]: 6.375083
[34]: 1.833810
[35]: 3.773387
[36]: 0.875965
[37]: 0.000000
[38]: 2.042444
[39]: 1.950521
[40]: 3.168527
[41]: 2.820475
[42]: 0.000000
[43]: 0.000000
[44]: 0.000000
[45]: 4.377554
[46]: 6.375685


Avarage Pooling Layer 8 Details:
Data: 
[0]: 0.364610
[1]: 0.724312
[2]: 0.377752
[3]: 1.176381
[4]: 1.450641
[5]: 0.837630
[6]: 0.662775
[7]: 0.000000
[8]: 0.971765
[9]: 0.000000
[10]: 0.836983
[11]: 1.258456
[12]: 0.990720
[13]: 0.000000
[14]: 0.000000
[15]: 0.497465
[16]: 3.187541
[17]: 2.803599
[18]: 0.437982
[19]: 1.996482
[20]: 2.994501
[21]: 0.000000
[22]: 2.188777


======================== Convolution Layer Details ========================
Input Size : 49
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : -0.132928

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.018376
              0 |     1 |      0.149403
              0 |     2 |      0.009077
              1 |     0 |     -0.443022
              1 |     1 |      0.130254
              1 |     2 |      0.174490
              2 |     0 |     -0.347932
              2 |     1 |      0.301881
              2 |     2 |     -0.286693
              3 |     0 |     -0.450529
              3 |     1 |     -0.040445
              3 |     2 |      0.238143
              4 |     0 |      0.463737
              4 |     1 |      0.035613
              4 |     2 |     -0.457479
              5 |     0 |      0.146063
              5 |     1 |     -0.118701
              5 |     2 |     -0.001376
==========================================================================


Output Layer 9 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 0.000000
[3]: 0.000000
[4]: 0.000000
[5]: 0.000000
[6]: 0.000000
[7]: 0.000000
[8]: 2.139283
[9]: 0.000000
[10]: 0.000000
[11]: 0.000000
[12]: 0.000000
[13]: 1.209056
[14]: 0.000000
[15]: 0.000000
[16]: 0.000000
[17]: 0.571172
[18]: 0.000000
[19]: 0.000000
[20]: 0.000000
[21]: 1.144004
[22]: 0.000000
[23]: 1.994367
[24]: 0.266659
[25]: 0.000000
[26]: 0.000000
[27]: 0.000000
[28]: 0.000000
[29]: 0.000000
[30]: 0.000000
[31]: 0.000000
[32]: 0.000000
[33]: 3.297619
[34]: 0.000000
[35]: 0.000000
[36]: 0.000000
[37]: 0.000000
[38]: 0.000000
[39]: 0.000000
[40]: 0.555297
[41]: 0.000000
[42]: 0.000000
[43]: 0.000000
[44]: 0.000000
[45]: 0.000000
[46]: 4.641613


Avarage Pooling Layer 9 Details:
Data: 
[0]: 0.000000
[1]: 0.000000
[2]: 0.000000
[3]: 0.000000
[4]: 1.069641
[5]: 0.000000
[6]: 0.604528
[7]: 0.000000
[8]: 0.285586
[9]: 0.000000
[10]: 0.572002
[11]: 0.997184
[12]: 0.133330
[13]: 0.000000
[14]: 0.000000
[15]: 0.000000
[16]: 1.648809
[17]: 0.000000
[18]: 0.000000
[19]: 0.000000
[20]: 0.277648
[21]: 0.000000
[22]: 0.000000


======================== Convolution Layer Details ========================
Input Size : 49
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : 0.386715

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.119215
              0 |     1 |      0.345829
              0 |     2 |      0.346190
              1 |     0 |      0.414592
              1 |     1 |      0.053225
              1 |     2 |     -0.447657
              2 |     0 |      0.232984
              2 |     1 |     -0.239239
              2 |     2 |      0.115697
              3 |     0 |     -0.476827
              3 |     1 |     -0.031526
              3 |     2 |      0.136335
              4 |     0 |      0.379297
              4 |     1 |     -0.163361
              4 |     2 |      0.383796
              5 |     0 |      0.462899
              5 |     1 |     -0.048612
              5 |     2 |     -0.019493
==========================================================================


Output Layer 10 Details:
Data: 
[0]: 1.545189
[1]: 0.074331
[2]: 0.000000
[3]: 1.062482
[4]: 0.000000
[5]: 0.941627
[6]: 0.000000
[7]: 2.273781
[8]: 2.990069
[9]: 0.727414
[10]: 0.000000
[11]: 2.081377
[12]: 0.000000
[13]: 2.466280
[14]: 0.451281
[15]: 3.155857
[16]: 0.507565
[17]: 2.737237
[18]: 0.000000
[19]: 0.952777
[20]: 0.000000
[21]: 2.317426
[22]: 6.643570
[23]: 3.355437
[24]: 1.862272
[25]: 0.126330
[26]: 0.000000
[27]: 0.000000
[28]: 0.907071
[29]: 0.963919
[30]: 0.000000
[31]: 1.525866
[32]: 0.000000
[33]: 1.065611
[34]: 8.589503
[35]: 1.896349
[36]: 1.239912
[37]: 0.425397
[38]: 0.730703
[39]: 1.486846
[40]: 3.720455
[41]: 5.065617
[42]: 0.000000
[43]: 0.405447
[44]: 0.221783
[45]: 4.818615
[46]: 6.658730


Avarage Pooling Layer 10 Details:
Data: 
[0]: 0.809760
[1]: 0.531241
[2]: 0.470813
[3]: 1.136891
[4]: 1.858742
[5]: 1.040689
[6]: 1.233140
[7]: 1.803569
[8]: 1.622401
[9]: 0.476389
[10]: 1.158713
[11]: 4.999503
[12]: 0.994301
[13]: 0.000000
[14]: 0.935495
[15]: 0.762933
[16]: 0.532806
[17]: 5.242926
[18]: 0.832655
[19]: 1.108775
[20]: 4.393036
[21]: 0.202723
[22]: 2.520199


Global Avarage Pooling Layer 1 Details:
Data: 
[0]: 0.162616


Global Avarage Pooling Layer 2 Details:
Data: 
[0]: 3.492623


Global Avarage Pooling Layer 3 Details:
Data: 
[0]: 0.385253


Global Avarage Pooling Layer 4 Details:
Data: 
[0]: 0.070411


Global Avarage Pooling Layer 5 Details:
Data: 
[0]: 1.096688


Global Avarage Pooling Layer 6 Details:
Data: 
[0]: 1.407697


Global Avarage Pooling Layer 7 Details:
Data: 
[0]: 0.787833


Global Avarage Pooling Layer 8 Details:
Data: 
[0]: 1.032973


Global Avarage Pooling Layer 9 Details:
Data: 
[0]: 0.242988


Global Avarage Pooling Layer 10 Details:
Data: 
[0]: 1.507291


Dense Layer Details:
Weights: 
[0]: -0.475008
[1]: -0.463082
[2]: -0.019215
[3]: 0.048070
[4]: -0.094541
[5]: 0.044396
[6]: 0.164758
[7]: 0.083603
[8]: 0.120999
[9]: -0.370365
Bias: 0.274666


Dense Layer 1 Details:
Data: 
[0]: 0.238187


Dense Layer Details:
Weights: 
[0]: 0.305734
[1]: 0.471050
[2]: -0.067020
[3]: -0.411796
[4]: -0.057983
[5]: 0.481791
[6]: 0.468966
[7]: -0.095447
[8]: -0.169424
[9]: 0.490706
Bias: 0.296893


Dense Layer 2 Details:
Data: 
[0]: 0.000000


Dense Layer Details:
Weights: 
[0]: -0.126149
[1]: -0.192981
[2]: -0.428903
[3]: 0.429472
[4]: 0.128365
[5]: 0.422339
[6]: 0.243312
[7]: 0.350547
[8]: -0.353366
[9]: -0.024718
Bias: -0.443399


Dense Layer 3 Details:
Data: 
[0]: 0.000000


Dense Layer Details:
Weights: 
[0]: -0.204096
[1]: -0.249722
[2]: -0.071504
[3]: 0.231107
[4]: 0.222035
[5]: -0.257575
[6]: -0.071025
[7]: 0.290898
[8]: 0.124710
[9]: -0.006646
Bias: 0.301084


Dense Layer 4 Details:
Data: 
[0]: 0.235464


Dense Layer Details:
Weights: 
[0]: 0.311166
[1]: -0.231230
[2]: -0.284753
[3]: 0.158132
[4]: -0.267693
[5]: -0.119668
[6]: -0.257802
[7]: 0.123497
[8]: -0.380133
[9]: 0.104056
Bias: -0.129492


Dense Layer 5 Details:
Data: 
[0]: 0.000000


Dense Layer Details:
Weights: 
[0]: -0.374901
[1]: 0.034324
[2]: -0.111329
[3]: -0.106954
[4]: 0.432351
[5]: -0.472030
[6]: -0.402822
[7]: -0.235723
[8]: 0.195534
[9]: 0.345988
Bias: 0.025555


Dense Layer 6 Details:
Data: 
[0]: 0.000000


Dense Layer Details:
Weights: 
[0]: -0.492099
[1]: 0.290884
[2]: -0.116343
[3]: -0.370521
[4]: -0.342840
[5]: -0.112897
[6]: -0.462142
[7]: -0.227692
[8]: 0.183953
[9]: -0.300973
Bias: -0.448968


Dense Layer 7 Details:
Data: 
[0]: 0.000000


Dense Layer Details:
Weights: 
[0]: 0.201003
[1]: 0.259511
[2]: -0.404393
[3]: 0.371396
[4]: 0.049504
[5]: 0.006739
[6]: 0.268370
[7]: 0.487641
[8]: -0.211089
[9]: 0.230308
Bias: -0.212945


Dense Layer 8 Details:
Data: 
[0]: 0.000000


Dense Layer Details:
Weights: 
[0]: 0.029164
[1]: 0.164736
[2]: -0.285066
[3]: -0.098049
[4]: 0.085328
[5]: 0.101551
[6]: -0.227752
[7]: 0.179619
[8]: -0.150712
[9]: -0.013149
Bias: 0.005524


Dense Layer 9 Details:
Data: 
[0]: 0.000000


Dense Layer Details:
Weights: 
[0]: -0.161765
[1]: 0.220103
[2]: 0.276931
[3]: 0.376982
[4]: -0.063132
[5]: -0.066888
[6]: -0.183457
[7]: -0.355867
[8]: -0.059663
[9]: 0.251827
Bias: 0.457924


Dense Layer 10 Details:
Data: 
[0]: 1.296163


Dense Layer Details:
Weights: 
[0]: 0.328026
[1]: 0.127924
[2]: 0.016809
[3]: -0.494887
[4]: 0.437737
[5]: 0.049604
[6]: -0.302241
[7]: 0.243640
[8]: -0.137208
[9]: -0.053035
Bias: -0.351006


Dense Layer 11 Details:
Data: 
[0]: 0.000000


Dense Layer Details:
Weights: 
[0]: -0.358433
[1]: -0.181744
[2]: 0.427515
[3]: 0.251454
[4]: 0.191898
[5]: 0.228705
[6]: -0.161185
[7]: -0.038313
[8]: 0.071824
[9]: 0.144387
Bias: -0.281476


Dense Layer 12 Details:
Data: 
[0]: 1.294736


Dense Layer Details:
Weights: 
[0]: 0.239493
[1]: 0.162235
[2]: -0.310485
[3]: -0.321335
[4]: 0.319025
[5]: -0.143491
[6]: 0.349404
[7]: 0.438650
[8]: 0.385664
[9]: -0.139476
Bias: -0.170122


Dense Layer 13 Details:
Data: 
[0]: 0.000000


Dense Layer Details:
Weights: 
[0]: -0.233649
[1]: 0.061062
[2]: 0.276094
[3]: 0.307690
[4]: 0.348954
[5]: -0.131281
[6]: -0.435313
[7]: -0.297684
[8]: -0.171822
[9]: 0.180240
Bias: 0.291434


Dense Layer 14 Details:
Data: 
[0]: 1.133079


Dense Layer Details:
Weights: 
[0]: 0.123774
[1]: 0.272135
[2]: -0.230849
[3]: 0.120207
[4]: 0.316269
[5]: -0.472905
[6]: -0.107404
[7]: -0.140514
[8]: 0.380323
[9]: 0.086974
Bias: -0.231224


Dense Layer 15 Details:
Data: 
[0]: 0.000000


Dense Layer Details:
Weights: 
[0]: -0.178291
[1]: 0.466665
[2]: 0.231505
[3]: -0.101923
[4]: -0.025071
[5]: -0.374691
[6]: -0.432219
[7]: -0.299200
[8]: 0.339516
[9]: 0.252562
[10]: -0.186916
[11]: -0.490420
[12]: -0.485350
[13]: -0.283229
[14]: -0.233408
Bias: 0.108908


Dense Layer 1 Details:
Data: 
[0]: 0.055341


Dense Layer Details:
Weights: 
[0]: 0.409348
[1]: -0.086039
[2]: -0.050914
[3]: 0.280512
[4]: -0.430389
[5]: 0.460090
[6]: -0.267070
[7]: 0.357117
[8]: 0.065372
[9]: -0.300736
[10]: -0.463733
[11]: 0.031952
[12]: 0.023204
[13]: -0.005317
[14]: -0.354710
Bias: 0.380937


Dense Layer 2 Details:
Data: 
[0]: 0.585296


Dense Layer Details:
Weights: 
[0]: 0.407583
[1]: 0.255387
[2]: 0.293272
[3]: 0.019682
[4]: -0.210822
[5]: -0.279790
[6]: -0.430803
[7]: 0.490849
[8]: -0.299731
[9]: 0.418598
[10]: 0.378596
[11]: 0.064159
[12]: 0.322107
[13]: -0.351984
[14]: 0.212398
Bias: -0.227379


Dense Layer 3 Details:
Data: 
[0]: -0.134773


Dense Layer Details:
Weights: 
[0]: 0.445926
[1]: -0.316030
[2]: 0.477752
[3]: -0.427950
[4]: 0.451145
[5]: 0.395984
[6]: 0.301617
[7]: 0.274378
[8]: 0.472943
[9]: -0.244666
[10]: -0.109081
[11]: -0.326909
[12]: -0.359852
[13]: -0.034725
[14]: 0.371409
Bias: 0.263023


Dense Layer 4 Details:
Data: 
[0]: 0.256676


Dense Layer Details:
Weights: 
[0]: -0.379325
[1]: -0.307230
[2]: 0.380541
[3]: -0.255318
[4]: -0.125171
[5]: 0.258274
[6]: -0.183630
[7]: -0.270720
[8]: 0.006521
[9]: -0.394371
[10]: -0.197210
[11]: 0.498124
[12]: -0.031432
[13]: -0.280054
[14]: 0.129963
Bias: 0.284347


Dense Layer 5 Details:
Data: 
[0]: 0.121398


Dense Layer Details:
Weights: 
[0]: 0.027440
[1]: 0.184019
[2]: -0.189973
[3]: 0.129286
[4]: -0.089879
[5]: 0.397638
[6]: 0.101561
[7]: -0.058350
[8]: 0.315043
[9]: -0.073513
[10]: 0.468957
[11]: -0.247622
[12]: 0.209823
[13]: -0.499179
[14]: 0.303727
Bias: -0.252314


Dense Layer 6 Details:
Data: 
[0]: -0.278398


Softmax Layer 1 Details:
Data: 
[0]: 0.153062


Softmax Layer 2 Details:
Data: 
[0]: 0.260031


Softmax Layer 3 Details:
Data: 
[0]: 0.126562


Softmax Layer 4 Details:
Data: 
[0]: 0.187201


Softmax Layer 5 Details:
Data: 
[0]: 0.163515


Softmax Layer 6 Details:
Data: 
[0]: 0.109629

