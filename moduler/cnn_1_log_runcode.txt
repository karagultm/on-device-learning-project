
Sensor Data:
Total data count: 110
1 - User: 33, Activity: Jogging, Timestamp: 49105962326000, X: -0.694638, Y: 12.680544, Z: 0.503953
2 - User: 33, Activity: Jogging, Timestamp: 49106062271000, X: 5.012288, Y: 11.264028, Z: 0.953424
3 - User: 33, Activity: Jogging, Timestamp: 49106112167000, X: 4.903325, Y: 10.882658, Z: -0.081722
4 - User: 33, Activity: Jogging, Timestamp: 49106222305000, X: -0.612916, Y: 18.496431, Z: 3.023717
5 - User: 33, Activity: Jogging, Timestamp: 49106332290000, X: -1.184970, Y: 12.108489, Z: 7.205164
6 - User: 33, Activity: Jogging, Timestamp: 49106442306000, X: 1.375655, Y: -2.492524, Z: -6.510526
7 - User: 33, Activity: Jogging, Timestamp: 49106542312000, X: -0.612916, Y: 10.569390, Z: 5.706926
8 - User: 33, Activity: Jogging, Timestamp: 49106652389000, X: -0.503953, Y: 13.947236, Z: 7.055340
9 - User: 33, Activity: Jogging, Timestamp: 49106762313000, X: -8.430995, Y: 11.413852, Z: 5.134871
10 - User: 33, Activity: Jogging, Timestamp: 49106872299000, X: 0.953424, Y: 1.375655, Z: 1.648062
11 - User: 33, Activity: Jogging, Timestamp: 49106982315000, X: -8.199450, Y: 19.572440, Z: 2.724070
12 - User: 33, Activity: Walking, Timestamp: 49395742294000, X: 1.757025, Y: 11.032481, Z: -0.653777
13 - User: 33, Activity: Walking, Timestamp: 49395852340000, X: 2.982856, Y: 12.149350, Z: -1.307553
14 - User: 33, Activity: Walking, Timestamp: 49395962295000, X: -0.803601, Y: 12.721405, Z: -1.266692
15 - User: 33, Activity: Walking, Timestamp: 49396072311000, X: 0.190685, Y: 6.932757, Z: 0.531194
16 - User: 33, Activity: Walking, Timestamp: 49396172287000, X: -0.340509, Y: 6.319841, Z: 0.503953
17 - User: 33, Activity: Walking, Timestamp: 49396282333000, X: 0.463092, Y: 8.894087, Z: 5.788648
18 - User: 33, Activity: Walking, Timestamp: 49396382309000, X: 0.081722, Y: 7.246025, Z: 5.897611
19 - User: 33, Activity: Walking, Timestamp: 49396492294000, X: -0.762740, Y: 4.603678, Z: -2.642348
20 - User: 33, Activity: Walking, Timestamp: 49396592239000, X: -1.607201, Y: 7.545672, Z: 1.035146
21 - User: 33, Activity: Walking, Timestamp: 49396692276000, X: 1.457377, Y: 8.771504, Z: -0.463092
22 - User: 33, Activity: Walking, Timestamp: 49396802292000, X: 1.035146, Y: 10.038197, Z: -0.803601
23 - User: 33, Activity: Walking, Timestamp: 49396912338000, X: 2.873893, Y: 15.050485, Z: 0.653777
24 - User: 33, Activity: Walking, Timestamp: 49397012253000, X: -3.949901, Y: 13.633968, Z: -2.301839
25 - User: 33, Activity: Walking, Timestamp: 49397122299000, X: 4.372132, Y: 7.463951, Z: -0.108963
26 - User: 33, Activity: Walking, Timestamp: 49403532303000, X: 3.636633, Y: 7.886181, Z: -0.463092
27 - User: 33, Activity: Walking, Timestamp: 49403642318000, X: -0.762740, Y: 0.463092, Z: -2.369940
28 - User: 33, Activity: Walking, Timestamp: 49403752304000, X: 1.498238, Y: 17.815414, Z: 15.663400
29 - User: 33, Activity: Walking, Timestamp: 49403862289000, X: -3.827318, Y: 15.513576, Z: -0.994285
30 - User: 33, Activity: Walking, Timestamp: 49403972305000, X: 0.081722, Y: 9.915613, Z: 0.653777
31 - User: 33, Activity: Walking, Timestamp: 49404082596000, X: -0.463092, Y: 9.575105, Z: 0.463092
32 - User: 33, Activity: Walking, Timestamp: 49404142288000, X: 2.029432, Y: 9.956474, Z: 0.612916
33 - User: 33, Activity: Walking, Timestamp: 49404252304000, X: 2.764931, Y: 14.818938, Z: 1.225831
34 - User: 33, Activity: Upstairs, Timestamp: 49563452316000, X: 0.926184, Y: 11.686258, Z: 1.648062
35 - User: 33, Activity: Upstairs, Timestamp: 49563502365000, X: -0.422231, Y: 10.760075, Z: 1.144109
36 - User: 33, Activity: Upstairs, Timestamp: 49563602279000, X: 0.340509, Y: 6.633110, Z: 0.953424
37 - User: 33, Activity: Upstairs, Timestamp: 49563652206000, X: -0.190685, Y: 4.821603, Z: 0.721878
38 - User: 33, Activity: Upstairs, Timestamp: 49563752243000, X: 0.231546, Y: 4.058864, Z: 2.179256
39 - User: 33, Activity: Upstairs, Timestamp: 49563852249000, X: 3.636633, Y: 8.430995, Z: 7.818079
40 - User: 33, Activity: Upstairs, Timestamp: 49563952255000, X: 1.375655, Y: 7.273266, Z: 1.988571
41 - User: 33, Activity: Upstairs, Timestamp: 49564056503000, X: 2.451662, Y: 11.495573, Z: 1.225831
42 - User: 33, Activity: Upstairs, Timestamp: 49564122970000, X: 0.653777, Y: 7.818079, Z: 0.340509
43 - User: 33, Activity: Upstairs, Timestamp: 49564222122000, X: 0.844462, Y: 6.891896, Z: -0.463092
44 - User: 33, Activity: Upstairs, Timestamp: 49564322250000, X: 3.023717, Y: 8.962189, Z: -0.081722
45 - User: 33, Activity: Upstairs, Timestamp: 49564372269000, X: 3.949901, Y: 11.264028, Z: 2.410802
46 - User: 33, Activity: Upstairs, Timestamp: 49564472275000, X: -1.879608, Y: 16.589584, Z: 0.803601
47 - User: 33, Activity: Upstairs, Timestamp: 49564522232000, X: 2.111154, Y: 14.178781, Z: 0.463092
48 - User: 33, Activity: Upstairs, Timestamp: 49564632309000, X: -2.342700, Y: 11.754360, Z: 1.144109
49 - User: 33, Activity: Upstairs, Timestamp: 49564742294000, X: -0.190685, Y: 5.747787, Z: 0.762740
50 - User: 33, Activity: Upstairs, Timestamp: 49564792282000, X: 1.035146, Y: 3.909040, Z: 1.184970
51 - User: 33, Activity: Upstairs, Timestamp: 49564892319000, X: 2.451662, Y: 3.868179, Z: 4.712640
52 - User: 33, Activity: Upstairs, Timestamp: 49564942306000, X: 1.566340, Y: 8.008764, Z: 5.788648
53 - User: 33, Activity: Upstairs, Timestamp: 49565052292000, X: -2.342700, Y: 8.117727, Z: 2.342700
54 - User: 33, Activity: Upstairs, Timestamp: 49565162308000, X: 1.116869, Y: 9.915613, Z: 1.225831
55 - User: 33, Activity: Upstairs, Timestamp: 49565263901000, X: 1.498238, Y: 8.812365, Z: 0.040861
56 - User: 33, Activity: Upstairs, Timestamp: 49565362259000, X: 0.081722, Y: 7.123442, Z: 0.503953
57 - User: 33, Activity: Upstairs, Timestamp: 49565462326000, X: 1.988571, Y: 13.947236, Z: 2.029432
58 - User: 33, Activity: Upstairs, Timestamp: 49565572342000, X: -2.982856, Y: 13.947236, Z: 1.144109
59 - User: 33, Activity: Upstairs, Timestamp: 49565682297000, X: 0.272407, Y: 11.727119, Z: 0.190685
60 - User: 33, Activity: Upstairs, Timestamp: 49565792312000, X: 1.457377, Y: 8.117727, Z: 0.422231
61 - User: 33, Activity: Upstairs, Timestamp: 49565902298000, X: 1.307553, Y: 4.481094, Z: 1.307553
62 - User: 33, Activity: Upstairs, Timestamp: 49566012283000, X: 2.683209, Y: 6.047434, Z: 6.442424
63 - User: 33, Activity: Upstairs, Timestamp: 49566062271000, X: 0.762740, Y: 9.425281, Z: 7.668256
64 - User: 33, Activity: Upstairs, Timestamp: 49566172317000, X: -2.914754, Y: 5.897611, Z: 2.533385
65 - User: 33, Activity: Upstairs, Timestamp: 49566282303000, X: 0.721878, Y: 8.962189, Z: 1.757025
66 - User: 33, Activity: Upstairs, Timestamp: 49566392319000, X: 1.307553, Y: 7.436710, Z: -0.000000
67 - User: 33, Activity: Upstairs, Timestamp: 49566492264000, X: 0.612916, Y: 7.545672, Z: 0.531194
68 - User: 33, Activity: Upstairs, Timestamp: 49566602310000, X: 1.035146, Y: 12.980191, Z: 2.111154
69 - User: 33, Activity: Upstairs, Timestamp: 49566712295000, X: -0.108963, Y: 15.785983, Z: 0.340509
70 - User: 33, Activity: Upstairs, Timestamp: 49566822311000, X: -1.729784, Y: 11.727119, Z: 1.879608
71 - User: 33, Activity: Upstairs, Timestamp: 49566922287000, X: 2.070293, Y: 6.210878, Z: -0.108963
72 - User: 33, Activity: Upstairs, Timestamp: 49578422226000, X: -1.076008, Y: 13.102775, Z: -1.879608
73 - User: 33, Activity: Upstairs, Timestamp: 49578522354000, X: -0.340509, Y: 13.824653, Z: 0.190685
74 - User: 33, Activity: Upstairs, Timestamp: 49578632309000, X: 1.729784, Y: 8.812365, Z: 2.301839
75 - User: 33, Activity: Upstairs, Timestamp: 49578742294000, X: 2.070293, Y: 5.788648, Z: 2.451662
76 - User: 33, Activity: Upstairs, Timestamp: 49578852310000, X: 0.381370, Y: 3.296124, Z: 3.595772
77 - User: 33, Activity: Upstairs, Timestamp: 49578962295000, X: 4.058864, Y: 5.325556, Z: 7.314127
78 - User: 7, Activity: Standing, Timestamp: 209133781495000, X: -7.270000, Y: 5.240000, Z: -0.530000
79 - User: 7, Activity: Standing, Timestamp: 209133821473000, X: -7.440000, Y: 5.410000, Z: -0.840000
80 - User: 7, Activity: Standing, Timestamp: 209133861482000, X: -8.200000, Y: 5.410000, Z: -1.120000
81 - User: 7, Activity: Standing, Timestamp: 209133901582000, X: -8.240000, Y: 5.220000, Z: -1.180000
82 - User: 7, Activity: Standing, Timestamp: 209133981507000, X: -8.010000, Y: 5.330000, Z: -1.230000
83 - User: 7, Activity: Standing, Timestamp: 209134021516000, X: -8.080000, Y: 5.330000, Z: -1.230000
84 - User: 7, Activity: Standing, Timestamp: 209134061524000, X: -8.310000, Y: 5.480000, Z: -1.080000
85 - User: 7, Activity: Standing, Timestamp: 209134101533000, X: -8.350000, Y: 5.480000, Z: -0.690000
86 - User: 7, Activity: Standing, Timestamp: 209134181520000, X: -8.010000, Y: 6.130000, Z: 0.890000
87 - User: 7, Activity: Standing, Timestamp: 209134221559000, X: -8.120000, Y: 6.510000, Z: 0.570000
88 - User: 7, Activity: Standing, Timestamp: 209134261506000, X: -8.200000, Y: 5.280000, Z: -0.720000
89 - User: 7, Activity: Standing, Timestamp: 209134301484000, X: -8.280000, Y: 4.750000, Z: -1.140000
90 - User: 19, Activity: Sitting, Timestamp: 131621971498000, X: 8.920000, Y: -1.270000, Z: 2.300000
91 - User: 19, Activity: Sitting, Timestamp: 131622051515000, X: 8.960000, Y: -1.270000, Z: 2.340000
92 - User: 19, Activity: Sitting, Timestamp: 131622091524000, X: 8.920000, Y: -1.270000, Z: 2.220000
93 - User: 19, Activity: Sitting, Timestamp: 131622131471000, X: 8.960000, Y: -1.310000, Z: 2.260000
94 - User: 19, Activity: Sitting, Timestamp: 131622171541000, X: 8.920000, Y: -1.330000, Z: 2.180000
95 - User: 19, Activity: Sitting, Timestamp: 131622211580000, X: 8.850000, Y: -1.420000, Z: 2.260000
96 - User: 19, Activity: Sitting, Timestamp: 131622291475000, X: 8.880000, Y: -1.380000, Z: 2.410000
97 - User: 19, Activity: Sitting, Timestamp: 131622331483000, X: 8.920000, Y: -1.310000, Z: 2.300000
98 - User: 19, Activity: Sitting, Timestamp: 131622371522000, X: 8.920000, Y: -1.140000, Z: 2.260000
99 - User: 19, Activity: Sitting, Timestamp: 131622451479000, X: 8.960000, Y: -1.120000, Z: 2.340000
100 - User: 19, Activity: Sitting, Timestamp: 131622491487000, X: 9.040000, Y: -1.120000, Z: 2.410000
101 - User: 19, Activity: Sitting, Timestamp: 131622531465000, X: 8.880000, Y: -1.120000, Z: 2.370000
102 - User: 19, Activity: Sitting, Timestamp: 131622571443000, X: 8.880000, Y: -1.140000, Z: 2.370000
103 - User: 19, Activity: Sitting, Timestamp: 131622611635000, X: 8.920000, Y: -1.230000, Z: 2.450000
104 - User: 19, Activity: Sitting, Timestamp: 131622691469000, X: 8.920000, Y: -1.230000, Z: 2.450000
105 - User: 19, Activity: Sitting, Timestamp: 131622731477000, X: 8.770000, Y: -1.330000, Z: 2.530000
106 - User: 19, Activity: Sitting, Timestamp: 131622771486000, X: 8.960000, Y: -1.380000, Z: 2.600000
107 - User: 19, Activity: Sitting, Timestamp: 131622851472000, X: 8.500000, Y: -1.500000, Z: 2.560000
108 - User: 19, Activity: Sitting, Timestamp: 131622891511000, X: 8.270000, Y: -1.650000, Z: 2.110000
109 - User: 19, Activity: Sitting, Timestamp: 131622931490000, X: 8.960000, Y: -1.460000, Z: 2.300000
110 - User: 19, Activity: Sitting, Timestamp: 131622971498000, X: 9.230000, Y: -1.460000, Z: 2.260000


======================== Convolution Layer Details ========================
Input Size : 110
Kernel Size: 3
Stride     : 1
Filter Size: 6
Bias       : -0.446013

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.494659
              0 |     1 |     -0.487793
              0 |     2 |      0.045335
              1 |     0 |      0.417264
              1 |     1 |     -0.009171
              1 |     2 |     -0.106952
              2 |     0 |     -0.255364
              2 |     1 |     -0.266717
              2 |     2 |     -0.017533
==========================================================================


Output Layer 1 Details:
Data: 
[0]: -8.532137
[1]: -5.030291
[2]: -0.563040
[3]: -3.750024
[4]: -11.251555
[5]: -7.471039
[6]: -1.415258
[7]: -4.213308
[8]: -11.985704
[9]: -3.112990
[10]: -0.909006
[11]: -0.915867
[12]: -9.976614
[13]: -3.711063
[14]: 2.537183
[15]: 0.913076
[16]: -6.909028
[17]: -15.151718
[18]: -8.047311
[19]: -2.464967
[20]: -4.883828
[21]: 2.877223
[22]: 3.528030
[23]: 0.893632
[24]: -7.113869
[25]: -6.987312
[26]: -0.774164
[27]: -0.989717
[28]: -11.491319
[29]: -6.862040
[30]: -2.554691
[31]: 5.871908
[32]: -4.575607
[33]: -13.762478
[34]: -2.104608
[35]: -3.528897
[36]: -8.785893
[37]: 3.568572
[38]: -0.569574
[39]: 2.236289
[40]: -9.091204
[41]: -9.600782
[42]: -1.957673
[43]: -2.138380
[44]: -8.618867
[45]: -3.413679
[46]: -0.126912
[47]: -2.875856
[48]: -10.130743
[49]: -2.410233
[50]: -0.520238
[51]: -0.220516
[52]: 937406463118184101684152414077793891529774612624171966699226908039859834296205119920247062260681448357367555548166230081958686621854010867215595662804475260768210936714233730711669253020261261594910628869434210380820755390957027852288.000000
[53]: 14260163245293940953494440054151115032887724529429805144627882173640056156256205352252399796175770017994803136603939335099491494669487498566093823877265846492310636159908245654996192063766780933411459756163349456649386025127475975028736.000000
[54]: 13653174203901486076772663024719088846210206823034438243883339678256181773591082255685959592158664977502373707546237967518415631244962392945874775310069729080975637786634271525154108162805489219199960472191365286048134317854338584674304.000000
[55]: -0.224729
[56]: nan
[57]: nan
[58]: nan
[59]: -0.446013
[60]: nan
[61]: nan
[62]: nan
[63]: -1.939067
[64]: nan
[65]: nan
[66]: nan
[67]: 0.393524
[68]: 1.272222
[69]: -2.614393
[70]: -10.634530
[71]: -4.630925
[72]: -3.153215
[73]: 0.211567
[74]: 0.324481
[75]: 1.886071
[76]: -0.413351
[77]: -4.169886
[78]: -6.306576
[79]: -8.068901
[80]: -1.664040
[81]: -2.955981
[82]: -0.207880
[83]: -2.765123
[84]: 0.687615
[85]: -5.498209
[86]: -10.775852
[87]: -2.422521
[88]: -2.374705
[89]: -0.453442
[90]: -1.648325
[91]: 2.652129
[92]: -1.860849
[93]: -1.958165
[94]: -5.589763
[95]: -8.223937
[96]: -0.633227
[97]: -5.022085
[98]: -2.690107
[99]: -3.658142
[100]: -0.585778
[101]: -6.342343
[102]: -6.122548
[103]: 0.111139
[104]: -2.158652
[105]: -1.090914
[106]: -5.354985
[107]: -3.715960


Avarage Pooling Layer 1 Details:
Data: 
[0]: -6.781214
[1]: -2.156532
[2]: -9.361297
[3]: -2.814283
[4]: -7.549347
[5]: -0.912437
[6]: -6.843838
[7]: 1.725129
[8]: -11.030373
[9]: -5.256139
[10]: -1.003302
[11]: 2.210831
[12]: -7.050591
[13]: -0.881941
[14]: -9.176680
[15]: 1.658609
[16]: -9.169043
[17]: -2.816753
[18]: -2.608660
[19]: 0.833358
[20]: -9.345993
[21]: -2.048026
[22]: -6.016273
[23]: -1.501384
[24]: -6.270488
[25]: -0.370377
[26]: 7598784854206062439338860024482657682549098252132367825933744795478160348919894896627141230430772611117525314975115377250166793824295861650301682711335443763209639533094173866891552799558642329608432927119406592147685906545637427511296.000000
[27]: 6826587101950743038386331512359544423105103411517219121941669839128090886795541127842979796079332488751186853773118983759207815622481196472937387655034864540487818893317135762577054081402744609599980236095682643024067158927169292337152.000000
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: -0.671086
[35]: -7.632728
[36]: -1.470824
[37]: 1.105276
[38]: -2.291618
[39]: -7.187739
[40]: -2.310010
[41]: -1.486502
[42]: -2.405297
[43]: -6.599186
[44]: -1.414073
[45]: 0.501902
[46]: -1.909507
[47]: -6.906850
[48]: -2.827656
[49]: -3.174124
[50]: -3.464061
[51]: -3.005705
[52]: -1.624783
[53]: -4.535472


======================== Convolution Layer Details ========================
Input Size : 110
Kernel Size: 3
Stride     : 1
Filter Size: 6
Bias       : 0.100482

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |      0.489074
              0 |     1 |      0.414029
              0 |     2 |     -0.088885
              1 |     0 |     -0.283349
              1 |     1 |     -0.428709
              1 |     2 |      0.208792
              2 |     0 |      0.146626
              2 |     1 |     -0.081530
              2 |     2 |     -0.062029
==========================================================================


Output Layer 2 Details:
Data: 
[0]: -1.247311
[1]: 4.512814
[2]: 0.681095
[3]: 0.247288
[4]: -0.726595
[5]: 5.421156
[6]: 0.542987
[7]: 4.633507
[8]: -1.720891
[9]: 0.039818
[10]: -0.018052
[11]: 1.281277
[12]: 4.647915
[13]: 4.044009
[14]: -0.986314
[15]: -3.182207
[16]: 1.907621
[17]: 13.587420
[18]: 6.086892
[19]: 2.537119
[20]: -4.494616
[21]: -7.785726
[22]: -3.193981
[23]: 2.014773
[24]: -3.179197
[25]: 1.910834
[26]: -0.129298
[27]: 4.486632
[28]: 3.494692
[29]: 4.474707
[30]: 3.794817
[31]: -5.071788
[32]: -3.236420
[33]: 9.360101
[34]: 0.638545
[35]: 7.147122
[36]: -5.110255
[37]: -3.587087
[38]: 0.949423
[39]: -4.480588
[40]: -1.884368
[41]: 9.842960
[42]: 1.942751
[43]: 0.381657
[44]: -1.817485
[45]: 4.312120
[46]: -0.479245
[47]: 2.810641
[48]: 0.644957
[49]: 3.412711
[50]: 0.009036
[51]: 0.002782
[52]: 3316411899543446064570311403366340145948416848887959890232069372486087229445388089328688043013299950244574134282125858633340237878458141724566674029107650200223090583876312892851707723446984843389068626056744067651924771575401287778304.000000
[53]: 4359062430322418445829900844147625762168011903311510840702257565967216291139395297470918634647250628251688956207615596739034500780879329832798167838070374571730847289169366730254915113150740904396240406669171898305148251402380268011520.000000
[54]: -7839459272500116159448696328057215213474418564366490335439933643101928485249770914079040407500800739673757718962911069591662282573157085273475936516052045431317529676766041366494983424417159824837731259343812232328473171749037508919296.000000
[55]: -0.436788
[56]: nan
[57]: nan
[58]: nan
[59]: 0.100482
[60]: nan
[61]: nan
[62]: nan
[63]: 0.650923
[64]: nan
[65]: nan
[66]: nan
[67]: -0.868197
[68]: -2.524710
[69]: 3.845270
[70]: 1.840879
[71]: 3.315278
[72]: 2.431637
[73]: -3.767568
[74]: -5.851987
[75]: -2.440387
[76]: 0.157553
[77]: -3.997198
[78]: 6.249227
[79]: 5.525656
[80]: 2.465095
[81]: 0.089749
[82]: 0.787065
[83]: 0.623008
[84]: -1.762858
[85]: 7.283972
[86]: 2.249973
[87]: 1.267268
[88]: 1.507955
[89]: -0.975330
[90]: -5.791505
[91]: -1.956439
[92]: 1.463803
[93]: -5.956027
[94]: 5.534657
[95]: 5.856597
[96]: 0.861482
[97]: -0.783032
[98]: 1.550517
[99]: 0.962898
[100]: -0.021499
[101]: 4.711487
[102]: 0.121210
[103]: -1.321403
[104]: 1.804365
[105]: -0.336360
[106]: 0.376898
[107]: 2.100139


Avarage Pooling Layer 2 Details:
Data: 
[0]: 1.632752
[1]: 0.464192
[2]: 2.347281
[3]: 2.588247
[4]: -0.840536
[5]: 0.631613
[6]: 4.345962
[7]: -2.084261
[8]: 7.747520
[9]: 4.312005
[10]: -6.140171
[11]: -0.589604
[12]: -0.634181
[13]: 2.178667
[14]: 3.984700
[15]: -0.638485
[16]: 3.061841
[17]: 3.892833
[18]: -4.348671
[19]: -1.765582
[20]: 3.979296
[21]: 1.162204
[22]: 1.247317
[23]: 1.165698
[24]: 2.028834
[25]: 0.005909
[26]: 3837737164932931902198361285229795835419609100521252446547924487779461174867150335563074543680462801013891420841121106323954182044169163513270312698790143932657832875654576507703799982959347802313645454775017017508866576634574482178048.000000
[27]: -3919729636250058079724348164028607606737209282183245167719966821550964242624885457039520203750400369836878859481455534795831141286578542636737968258026022715658764838383020683247491712208579912418865629671906116164236585874518754459648.000000
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: 0.660280
[35]: 2.578078
[36]: -0.667965
[37]: -4.146187
[38]: -1.919823
[39]: 5.887442
[40]: 1.277422
[41]: 0.705036
[42]: 2.760557
[43]: 1.758621
[44]: 0.266313
[45]: -3.873972
[46]: -2.246112
[47]: 5.695627
[48]: 0.039225
[49]: 1.256708
[50]: 2.344994
[51]: -0.600097
[52]: 0.734002
[53]: 1.238518


======================== Convolution Layer Details ========================
Input Size : 110
Kernel Size: 3
Stride     : 1
Filter Size: 6
Bias       : -0.386624

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.228172
              0 |     1 |      0.315760
              0 |     2 |      0.405972
              1 |     0 |      0.281487
              1 |     1 |     -0.219535
              1 |     2 |     -0.285150
              2 |     0 |     -0.306635
              2 |     1 |     -0.314112
              2 |     2 |     -0.394864
==========================================================================


Output Layer 3 Details:
Data: 
[0]: -2.242982
[1]: -3.470794
[2]: 0.670512
[3]: -5.521743
[4]: -5.388052
[5]: -6.195863
[6]: 1.078941
[7]: -3.968977
[8]: -9.482771
[9]: -4.328950
[10]: -2.180321
[11]: 4.288392
[12]: 4.706738
[13]: 0.983714
[14]: 2.316652
[15]: 0.582717
[16]: 4.037638
[17]: -5.180218
[18]: -4.680967
[19]: -9.192405
[20]: -15.263208
[21]: -6.644253
[22]: 3.765879
[23]: -2.014333
[24]: -2.835684
[25]: -3.731969
[26]: 0.545710
[27]: 2.870005
[28]: -0.721774
[29]: -0.195121
[30]: -1.513359
[31]: -4.169564
[32]: 2.012836
[33]: -8.201385
[34]: 0.101708
[35]: -8.216331
[36]: -10.628412
[37]: 1.553668
[38]: -4.802990
[39]: -4.295733
[40]: 2.814739
[41]: -4.058011
[42]: -0.611212
[43]: -4.242968
[44]: -2.273410
[45]: -2.906357
[46]: 1.147711
[47]: -0.760933
[48]: -2.865461
[49]: -2.005312
[50]: -0.988331
[51]: 2.505436
[52]: 21111633634559835281366374968274794398595211310095084397766163191477063901366964900615687521989370133387277576465750537991888695644829933636708631467313174438574939732621353765217421627753329389592826643767365947115102433306619821424640.000000
[53]: 16794179324010287773897580618709241880344664260954882692697845596343146543204524167699050648223380702832250039028863346783023209058888555347809800268171433647632717899680613453674425235272850790937498161115324216091802371728514268266496.000000
[54]: 16394415035996438847492757582563405774635777282863550238523098809601702097340012212435070875386816931163542362904894386055887081847081513088430574462686734274722062655574879388912011034848797935740029186239569874718861612010585540526080.000000
[55]: 2.488095
[56]: nan
[57]: nan
[58]: nan
[59]: -0.386624
[60]: nan
[61]: nan
[62]: nan
[63]: -2.171401
[64]: nan
[65]: nan
[66]: nan
[67]: -0.642287
[68]: 1.664057
[69]: -3.522530
[70]: -7.569421
[71]: -3.478997
[72]: -9.750072
[73]: -7.264578
[74]: -2.701950
[75]: 0.298738
[76]: -4.652195
[77]: 1.509770
[78]: 2.013606
[79]: -3.472024
[80]: 2.950087
[81]: 0.537597
[82]: 1.059179
[83]: -1.656738
[84]: 5.735284
[85]: -3.319455
[86]: -9.174683
[87]: -2.040028
[88]: -7.470582
[89]: -6.651835
[90]: -3.744040
[91]: 1.713130
[92]: -7.164782
[93]: 1.275044
[94]: 2.944598
[95]: -4.718810
[96]: 0.352455
[97]: -2.922877
[98]: -2.383134
[99]: -2.629800
[100]: 2.154638
[101]: -3.311473
[102]: -6.983848
[103]: 0.088198
[104]: -1.770754
[105]: -1.444583
[106]: -1.363498
[107]: -2.851453


Avarage Pooling Layer 3 Details:
Data: 
[0]: -2.856888
[1]: -2.425616
[2]: -5.791957
[3]: -1.445018
[4]: -6.905860
[5]: 1.054035
[6]: 2.845226
[7]: 1.449684
[8]: -0.571290
[9]: -6.936686
[10]: -10.953731
[11]: 0.875773
[12]: -3.283827
[13]: 1.707857
[14]: -0.458448
[15]: -2.841461
[16]: -3.094274
[17]: -4.057312
[18]: -4.537372
[19]: -4.549362
[20]: -0.621636
[21]: -2.427090
[22]: -2.589884
[23]: 0.193389
[24]: -2.435387
[25]: 0.758553
[26]: 18952906479285060115624998439383269664915516683211051869555048468121342880584779102810453904507125465172803310132308456938523203209860955430610782928546830229827284572677930394047877690155029803949126156089581219724772663100301861978112.000000
[27]: 8197207517998219423746378791281702887317888641431775119261549404800851048670006106217535437693408465581771181452447193027943540923540756544215287231343367137361031327787439694456005517424398967870014593119784937359430806005292770263040.000000
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: -0.929237
[35]: -5.524209
[36]: -8.507325
[37]: -1.201606
[38]: -1.571212
[39]: -0.729209
[40]: 1.743842
[41]: -0.298779
[42]: 1.207914
[43]: -5.607356
[44]: -7.061208
[45]: -1.015455
[46]: -2.944869
[47]: -0.887106
[48]: -1.285211
[49]: -2.506467
[50]: -0.578417
[51]: -3.447825
[52]: -1.607669
[53]: -2.107476


======================== Convolution Layer Details ========================
Input Size : 110
Kernel Size: 3
Stride     : 1
Filter Size: 6
Bias       : 0.096789

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |      0.421110
              0 |     1 |     -0.390225
              0 |     2 |      0.381619
              1 |     0 |      0.032395
              1 |     1 |     -0.258721
              1 |     2 |      0.450560
              2 |     0 |     -0.144490
              2 |     1 |      0.420804
              2 |     2 |     -0.250755
==========================================================================


Output Layer 4 Details:
Data: 
[0]: -3.382480
[1]: 3.751443
[2]: 4.627420
[3]: 1.178136
[4]: 2.596036
[5]: 3.441668
[6]: 1.950925
[7]: 7.293833
[8]: -2.099353
[9]: 5.810784
[10]: -1.993496
[11]: 14.360621
[12]: -5.765006
[13]: 2.854506
[14]: 2.865526
[15]: 0.792830
[16]: -1.516408
[17]: 4.862148
[18]: 2.470639
[19]: -0.179910
[20]: 3.153846
[21]: 1.407317
[22]: -1.826247
[23]: 4.374007
[24]: 2.179802
[25]: 1.458731
[26]: -2.243409
[27]: 12.996121
[28]: -3.750235
[29]: 2.752938
[30]: 2.264285
[31]: -0.242601
[32]: 3.207369
[33]: 0.835976
[34]: -1.852161
[35]: 9.162552
[36]: 1.040923
[37]: -1.906934
[38]: -2.111870
[39]: 13.490529
[40]: -8.036769
[41]: 5.496798
[42]: 3.627647
[43]: 4.795522
[44]: -1.566775
[45]: 3.358524
[46]: 0.690571
[47]: 7.850704
[48]: -5.018528
[49]: 5.684888
[50]: -0.792375
[51]: 8.339389
[52]: 13406788867207239880483565080527120717081559742763379924032801251676261329355381849419995533182407187654181084836522677586762644561240281438973434877074717912277034978958495757423788295101542914040207462176865830415288051583432930623488.000000
[53]: -22498570960322162239883808678110609874392810387433877567512004198220032555239705549840674735384744644957044932423404443692649191689473943456061641053054998777487941780960815311666825880547131945862257541624668539745249042988705440071680.000000
[54]: 7725240904496157911326053249335370708717458325455035101427335778244182016158944924085273863233961137688595028169635738220690639942071069852004867632432371797209369649262778418307676482937941579893846734456118558628953215269506975268864.000000
[55]: 2.668049
[56]: nan
[57]: nan
[58]: nan
[59]: 0.096789
[60]: nan
[61]: nan
[62]: nan
[63]: -0.000459
[64]: nan
[65]: nan
[66]: nan
[67]: -1.347121
[68]: -3.894440
[69]: 4.618021
[70]: 0.813355
[71]: 1.334914
[72]: -3.340758
[73]: 13.419497
[74]: -9.981295
[75]: 3.705319
[76]: 2.613593
[77]: 4.054031
[78]: -2.425091
[79]: 4.434407
[80]: 10.083395
[81]: -11.088591
[82]: 10.367453
[83]: -3.031092
[84]: 1.498308
[85]: -3.221467
[86]: 9.256883
[87]: -2.987634
[88]: -4.043125
[89]: 15.274299
[90]: -11.174811
[91]: 4.165551
[92]: 1.088918
[93]: 6.736083
[94]: -6.013025
[95]: 6.286725
[96]: 7.162624
[97]: -8.375607
[98]: 9.875361
[99]: -2.944447
[100]: 4.334980
[101]: -1.238688
[102]: 5.072539
[103]: -1.034489
[104]: 1.925972
[105]: 3.288161
[106]: -0.457870
[107]: 2.110757


Avarage Pooling Layer 4 Details:
Data: 
[0]: 0.184482
[1]: 2.902778
[2]: 3.018852
[3]: 4.622379
[4]: 1.855715
[5]: 6.183562
[6]: -1.455250
[7]: 1.829178
[8]: 1.672870
[9]: 1.145364
[10]: 2.280582
[11]: 1.273880
[12]: 1.819267
[13]: 5.376356
[14]: -0.498648
[15]: 1.010842
[16]: 2.021673
[17]: 3.655195
[18]: -0.433006
[19]: 5.689330
[20]: -1.269986
[21]: 4.211584
[22]: 0.895874
[23]: 4.270638
[24]: 0.333180
[25]: 3.773507
[26]: -4545891046557461179700121798791744578655625322335248821739601473271885612942161850210339601101168728651431923793440883052943273564116831008544103087990140432605453401001159777121518792722794515911025039723901354664980495702636254724096.000000
[27]: 3862620452248078955663026624667685354358729162727517550713667889122091008079472462042636931616980568844297514084817869110345319971035534926002433816216185898604684824631389209153838241468970789946923367228059279314476607634753487634432.000000
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: 0.361791
[35]: 1.074135
[36]: 5.039369
[37]: -3.137988
[38]: 3.333812
[39]: 1.004658
[40]: -0.502598
[41]: 3.668180
[42]: -0.861579
[43]: 3.134624
[44]: 5.615587
[45]: -3.504630
[46]: 3.912501
[47]: 0.136850
[48]: -0.606491
[49]: 3.465457
[50]: 1.548146
[51]: 2.019025
[52]: 2.607066
[53]: 0.826443


======================== Convolution Layer Details ========================
Input Size : 110
Kernel Size: 3
Stride     : 1
Filter Size: 6
Bias       : -0.050279

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |      0.338313
              0 |     1 |      0.413205
              0 |     2 |      0.334468
              1 |     0 |     -0.000473
              1 |     1 |     -0.382199
              1 |     2 |     -0.277245
              2 |     0 |     -0.372402
              2 |     1 |      0.456725
              2 |     2 |      0.230461
==========================================================================


Output Layer 5 Details:
Data: 
[0]: 3.676679
[1]: -0.011826
[2]: 0.325968
[3]: 4.879830
[4]: 11.852567
[5]: -1.326570
[6]: 0.683119
[7]: 2.971226
[8]: 5.802725
[9]: 1.214837
[10]: -2.322014
[11]: 3.032656
[12]: -1.379475
[13]: 2.651890
[14]: 2.474828
[15]: 5.831143
[16]: 16.089792
[17]: 8.183315
[18]: 0.779028
[19]: -0.027459
[20]: -0.230198
[21]: -7.741527
[22]: -6.891291
[23]: -1.662819
[24]: 8.268132
[25]: 1.275156
[26]: 2.353499
[27]: 5.216746
[28]: 2.773145
[29]: 5.856030
[30]: -3.253414
[31]: 0.303544
[32]: 15.168478
[33]: -0.742275
[34]: 3.668759
[35]: 1.856270
[36]: -2.606170
[37]: -4.361398
[38]: -1.792686
[39]: 3.540064
[40]: 6.274866
[41]: 2.819949
[42]: 0.934040
[43]: 2.422103
[44]: 6.419317
[45]: -1.410002
[46]: 1.465286
[47]: 3.710818
[48]: 4.248933
[49]: 1.658661
[50]: -1.011505
[51]: 1.877612
[52]: -12321714371169655585412677113137702328375122354342632822552026533675961485955568267662568300737305333444102240102886583123124152982900037267252125161826714867482862004563716157517989859382783452339793801492588065632024947160972829655040.000000
[53]: -24419071233760112259893842415940749561073001550817175335054693438164650352682432482764414537983630931882036597341298626683575835386518167844350405345956571248727256209743882076197139134753378466397794550649262375014084809974303267225600.000000
[54]: 19910709079546806551251521795785167024329795416169313004488629723880986866315725416701918443619898861368549340019007754154929885047446597819389995516145786534847392374557952883348834375791688634095759807030663389299897284610420826439680.000000
[55]: 2.347295
[56]: nan
[57]: nan
[58]: nan
[59]: -0.050279
[60]: nan
[61]: nan
[62]: nan
[63]: -1.121856
[64]: nan
[65]: nan
[66]: nan
[67]: -3.035018
[68]: 4.020669
[69]: 8.090816
[70]: 5.246204
[71]: -0.639129
[72]: -2.300543
[73]: -2.551199
[74]: -9.370035
[75]: 1.878429
[76]: -0.459221
[77]: 6.071613
[78]: 3.214379
[79]: 5.397869
[80]: -1.313244
[81]: -1.956858
[82]: 8.043766
[83]: -2.583307
[84]: 5.895353
[85]: 7.580453
[86]: 7.911147
[87]: -4.315204
[88]: 0.391790
[89]: -1.305388
[90]: -9.148699
[91]: 3.074871
[92]: -1.652258
[93]: 5.240125
[94]: 1.999274
[95]: 5.259283
[96]: -0.238179
[97]: 2.086296
[98]: 6.423696
[99]: -2.885390
[100]: 3.910788
[101]: 3.167239
[102]: 2.601945
[103]: -0.802186
[104]: -0.611872
[105]: 1.568172
[106]: 3.431502
[107]: -0.009875


Avarage Pooling Layer 5 Details:
Data: 
[0]: 1.832426
[1]: 2.602899
[2]: 5.262998
[3]: 1.827173
[4]: 3.508781
[5]: 0.355321
[6]: 0.636208
[7]: 4.152985
[8]: 12.136554
[9]: 0.375784
[10]: -3.985862
[11]: -4.277055
[12]: 4.771644
[13]: 3.785122
[14]: 4.314588
[15]: -1.474935
[16]: 7.213101
[17]: 2.762515
[18]: -3.483784
[19]: 0.873689
[20]: 4.547407
[21]: 1.678072
[22]: 2.504657
[23]: 2.588052
[24]: 2.953797
[25]: 0.433054
[26]: -18370392802464882510646280410430477470169640850265972403126404060131543577618034943866576238761218179726108921107094119454417245042710813494152832314696169244828514863680745901459518755710020673052757929719161358444375139150372865572864.000000
[27]: 9955354539773403275625760897892583512164897708084656502244314861940493433157862708350959221809949430684274670009503877077464942523723298909694997758072893267423696187278976441674417187895844317047879903515331694649948642305210413219840.000000
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: 6.055743
[35]: 2.303538
[36]: -2.425871
[37]: -3.745803
[38]: 2.806196
[39]: 4.306124
[40]: -1.635051
[41]: 2.730229
[42]: 6.737903
[43]: 1.797971
[44]: -0.456799
[45]: -3.036914
[46]: 1.793934
[47]: 3.629279
[48]: 0.924058
[49]: 1.769153
[50]: 3.539013
[51]: 0.899880
[52]: 0.478150
[53]: 1.710814


======================== Convolution Layer Details ========================
Input Size : 110
Kernel Size: 3
Stride     : 1
Filter Size: 6
Bias       : 0.393246

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.300653
              0 |     1 |      0.141591
              0 |     2 |      0.000778
              1 |     0 |     -0.412412
              1 |     1 |     -0.332545
              1 |     2 |      0.406461
              2 |     0 |      0.255181
              2 |     1 |      0.007523
              2 |     2 |     -0.131733
==========================================================================


Output Layer 6 Details:
Data: 
[0]: -1.683597
[1]: -5.533891
[2]: 1.905325
[3]: 1.463299
[4]: -5.608053
[5]: -2.576608
[6]: 0.822683
[7]: 7.213872
[8]: -5.369684
[9]: -8.379846
[10]: 0.346077
[11]: 5.975236
[12]: 3.779433
[13]: -12.814379
[14]: -4.509729
[15]: -2.632641
[16]: -0.743851
[17]: 3.705999
[18]: 2.186638
[19]: 3.244846
[20]: -2.273814
[21]: -2.423811
[22]: 2.702765
[23]: 4.584272
[24]: -2.226033
[25]: -7.123429
[26]: -6.474804
[27]: 7.601666
[28]: 4.330137
[29]: -8.852408
[30]: -1.963984
[31]: -3.189550
[32]: 2.063393
[33]: 1.588293
[34]: -4.698591
[35]: 9.771302
[36]: -1.099801
[37]: -5.954425
[38]: -1.077679
[39]: 1.569461
[40]: 1.997494
[41]: -6.347641
[42]: 0.829852
[43]: 2.915035
[44]: -4.317758
[45]: -4.355262
[46]: 0.456391
[47]: 5.351192
[48]: -3.167390
[49]: -6.496757
[50]: 1.521196
[51]: 3.043846
[52]: 7043194078415389268474715154413523489106260039057031866981805913306338696940981396529316284543482875046355270939637378693154631783458864141321566670486595321870103657412236689123073031738319925832294365570001926368756088484331591303168.000000
[53]: -402211824471075118021538888600495538824118216669960500307647026185572907234549942436465767761999223354336638970906810811118753045621399273212664779444167243606036245756467656742411953348790552160292662728367572511961961433973680766976.000000
[54]: -13643384058072577427286606391101392808724623837356613951240109924560571488433275370791998865808985800183216487717240732197920067769209669971007828831444304611683617110480440814889491362371872643979566043313561741325680227592679519682560.000000
[55]: 0.425641
[56]: nan
[57]: nan
[58]: nan
[59]: 0.393246
[60]: nan
[61]: nan
[62]: nan
[63]: 1.546571
[64]: nan
[65]: nan
[66]: nan
[67]: -0.566465
[68]: -4.315669
[69]: 3.989635
[70]: 2.593483
[71]: 0.363238
[72]: 1.525969
[73]: 2.724603
[74]: 1.158138
[75]: -7.085800
[76]: 2.832610
[77]: -2.275831
[78]: 0.472809
[79]: -3.254881
[80]: 3.873486
[81]: -2.555943
[82]: -6.480608
[83]: 2.135637
[84]: -4.392180
[85]: 4.379007
[86]: -1.428565
[87]: 2.654374
[88]: -1.375477
[89]: 5.341554
[90]: 0.835777
[91]: -7.342439
[92]: 3.503625
[93]: -2.861245
[94]: 2.285835
[95]: -4.346295
[96]: 3.437194
[97]: -2.867510
[98]: -4.627610
[99]: 2.869552
[100]: -1.180534
[101]: 3.777094
[102]: -4.781590
[103]: -0.685881
[104]: 0.987406
[105]: 1.391686
[106]: -0.610411
[107]: -3.530305


Avarage Pooling Layer 6 Details:
Data: 
[0]: -3.608744
[1]: 1.684312
[2]: -4.092330
[3]: 4.018277
[4]: -6.874765
[5]: 3.160656
[6]: -4.517473
[7]: -3.571185
[8]: 1.481074
[9]: 2.715742
[10]: -2.348812
[11]: 3.643519
[12]: -4.674731
[13]: 0.563431
[14]: -2.261136
[15]: -2.576767
[16]: 1.825843
[17]: 2.536356
[18]: -3.527113
[19]: 0.245891
[20]: -2.175073
[21]: 1.872443
[22]: -4.336510
[23]: 2.903791
[24]: -4.832073
[25]: 2.282521
[26]: 3320491126972157295852678656986005924290199208430087507661603806964877010743991575694380755359374630992409393736708797292413681422355965099937018592270506822456493743870549081096275186281961606572881514913280280346940772809126640091136.000000
[27]: -6821692029036288713643303195550696404362311918678306975620054962280285744216637685395999432904492900091608243858620366098960033884604834985503914415722152305841808555240220407444745681185936321989783021656780870662840113796339759841280.000000
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: -0.163017
[35]: 1.478361
[36]: 2.125286
[37]: -2.963831
[38]: 0.278390
[39]: -1.391036
[40]: 0.658772
[41]: -2.172486
[42]: -0.006587
[43]: 0.612904
[44]: 1.983038
[45]: -3.253331
[46]: 0.321190
[47]: -1.030230
[48]: 0.284842
[49]: -0.879029
[50]: 1.298280
[51]: -2.733735
[52]: 1.189546
[53]: -2.070358


======================== Convolution Layer Details ========================
Input Size : 54
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : -0.358333

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.384762
              0 |     1 |     -0.297510
              0 |     2 |      0.248863
              1 |     0 |      0.481811
              1 |     1 |     -0.222221
              1 |     2 |     -0.427183
              2 |     0 |     -0.363735
              2 |     1 |      0.107471
              2 |     2 |      0.187307
              3 |     0 |     -0.466521
              3 |     1 |      0.039933
              3 |     2 |      0.478912
              4 |     0 |      0.007370
              4 |     1 |      0.225333
              4 |     2 |     -0.356655
              5 |     0 |      0.227714
              5 |     1 |      0.296808
              5 |     2 |      0.110767
==========================================================================


Output Layer 1 Details:
Data: 
[0]: -0.639443
[1]: 2.289158
[2]: 2.138150
[3]: 4.669361
[4]: -0.693571
[5]: -1.537720
[6]: -6.481553
[7]: -3.183860
[8]: 10.844347
[9]: 8.838286
[10]: -4.285864
[11]: 0.495207
[12]: -3.537966
[13]: 1.012117
[14]: -2.276587
[15]: 0.545426
[16]: 7.357275
[17]: 4.924999
[18]: -6.886946
[19]: -0.143704
[20]: 3.244231
[21]: 1.502316
[22]: -0.375961
[23]: 1.749197
[24]: 8544265615629596587179844861312749749073238133875205271998580524281173014483141227103897226616302384604995252693266086099619315773231108576048738019660385126296008469752595064220563197853983506142493515920523048273334467368140786368512.000000
[25]: -1959760238670040932378937576121214543796537085696620757744409619462154068686160460387777047518471138733729624516191958688376377897616447053376978468655272823352887759044261204522721756053502104677663612617401523980264791424035410935808.000000
[26]: nan
[27]: nan
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: 4.339540
[35]: 6.965617
[36]: 0.291725
[37]: -5.444258
[38]: -0.330522
[39]: 4.968481
[40]: -3.113621
[41]: -2.326006
[42]: 4.873725
[43]: 4.704648
[44]: 0.725620
[45]: -5.431365
[46]: -1.711926
[47]: 5.192374
[48]: -0.106674
[49]: 1.473960
[50]: 2.234014
[51]: -1.578501


Avarage Pooling Layer 1 Details:
Data: 
[0]: 0.824857
[1]: 3.403755
[2]: -1.115645
[3]: -4.832707
[4]: 9.841316
[5]: -1.895328
[6]: -1.262925
[7]: -0.865580
[8]: 6.141137
[9]: -3.515325
[10]: 2.373274
[11]: 0.686618
[12]: 3292252688479777827400453642595767602638350524089292257127085452409509472898490383358060089548915622935632814088537063705621468937807330761335879775502556151471560355354166929848920720900240700732414951651560762146534837972052687716352.000000
[13]: nan
[14]: nan
[15]: nan
[16]: nan
[17]: 5.652579
[18]: -2.576266
[19]: 2.318980
[20]: -2.719813
[21]: 4.789187
[22]: -2.352872
[23]: 1.740224
[24]: 0.683643
[25]: 0.327756


======================== Convolution Layer Details ========================
Input Size : 54
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : 0.329066

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.479278
              0 |     1 |     -0.202322
              0 |     2 |     -0.264306
              1 |     0 |     -0.418729
              1 |     1 |     -0.333247
              1 |     2 |      0.240440
              2 |     0 |      0.438688
              2 |     1 |      0.357295
              2 |     2 |     -0.251579
              3 |     0 |     -0.427000
              3 |     1 |      0.288385
              3 |     2 |     -0.474181
              4 |     0 |      0.310785
              4 |     1 |      0.020096
              4 |     2 |     -0.468963
              5 |     0 |      0.086779
              5 |     1 |     -0.362239
              5 |     2 |      0.378719
==========================================================================


Output Layer 2 Details:
Data: 
[0]: 0.560287
[1]: 1.523667
[2]: -1.210226
[3]: -0.434836
[4]: 2.786282
[5]: -4.598131
[6]: 5.230747
[7]: 5.326534
[8]: 3.251995
[9]: -0.537945
[10]: -7.150608
[11]: -2.661809
[12]: 5.174331
[13]: 0.004645
[14]: 4.560709
[15]: -2.129853
[16]: 2.923508
[17]: -3.289045
[18]: 1.798638
[19]: -3.251047
[20]: 3.666003
[21]: -1.109908
[22]: 1.174393
[23]: 0.286846
[24]: 6174325059883733697377787587481493703359329899902198912896190354650361342169103746042457317200882801036627074818113213372680732768152456276082779580410958742841879557670344289654394916596909647760504775190258187283966033793220752703488.000000
[25]: -12820281650761299558235594052285619447453559366577871233089473148972182264318505701744849530494434907975772024656726312215064676740173650249586489122971226855754647011530653430181652379089149849254793817911130743707774051738267989049344.000000
[26]: nan
[27]: nan
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: 2.133244
[35]: 0.120511
[36]: -6.569557
[37]: 2.862092
[38]: 2.860195
[39]: -1.179212
[40]: 1.530484
[41]: 1.076804
[42]: 3.297590
[43]: -0.819239
[44]: -5.506094
[45]: 3.927282
[46]: 0.517883
[47]: 0.651529
[48]: 2.078988
[49]: -1.918778
[50]: 2.472373
[51]: -0.422574


Avarage Pooling Layer 2 Details:
Data: 
[0]: 1.041977
[1]: -0.822531
[2]: -0.905925
[3]: 5.278641
[4]: 1.357025
[5]: -4.906208
[6]: 2.589488
[7]: 1.215428
[8]: -0.182769
[9]: -0.726205
[10]: 1.278048
[11]: 0.730619
[12]: -3322978295438782930428903232402062872047114733337836160096641397160910461074700977851196106646776053469572474919306549421191971986010596986751854771280134056456383726930154570263628731246120100747144521360436278211904008972523618172928.000000
[13]: nan
[14]: nan
[15]: nan
[16]: nan
[17]: 1.126877
[18]: -1.853733
[19]: 0.840491
[20]: 1.303644
[21]: 1.239175
[22]: -0.789406
[23]: 0.584706
[24]: 0.080105
[25]: 1.024900


======================== Convolution Layer Details ========================
Input Size : 54
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : 0.226371

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |      0.393643
              0 |     1 |     -0.352046
              0 |     2 |      0.456206
              1 |     0 |      0.071245
              1 |     1 |      0.346492
              1 |     2 |     -0.059526
              2 |     0 |      0.057268
              2 |     1 |      0.037492
              2 |     2 |     -0.475616
              3 |     0 |      0.022660
              3 |     1 |      0.425901
              3 |     2 |     -0.302698
              4 |     0 |      0.413633
              4 |     1 |      0.250664
              4 |     2 |     -0.451170
              5 |     0 |      0.425138
              5 |     1 |      0.387722
              5 |     2 |     -0.485839
==========================================================================


Output Layer 3 Details:
Data: 
[0]: -2.847232
[1]: 1.113697
[2]: 3.786262
[3]: -1.621824
[4]: -2.488281
[5]: 2.942604
[6]: -16.448368
[7]: 10.765129
[8]: 14.177291
[9]: -3.319163
[10]: -5.944835
[11]: -1.741984
[12]: -3.071041
[13]: 10.403258
[14]: -11.813108
[15]: 3.366165
[16]: 10.527843
[17]: -1.304144
[18]: -7.474190
[19]: 2.373523
[20]: 0.814324
[21]: -1.986766
[22]: 0.635523
[23]: 0.982601
[24]: 2274847311965273651525711397000451741845636785128509942708821312015948199444500105198207710412024620111808824158299839051845291578477327877112713323685177664764923039668571531500519486645669839067101112961901132078807164498981312004096.000000
[25]: -8785844953393130907433594881619537659564860825715649346020305122594811711968803514859177205769918478205890826660809674968745954250020666021865491120071948036813562288295513699209033615774772129867798759736478114957209541117613413761024.000000
[26]: nan
[27]: nan
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: 9.332608
[35]: 6.426743
[36]: -8.762754
[37]: -5.123224
[38]: 4.573616
[39]: -1.924745
[40]: -3.351050
[41]: 0.625053
[42]: 7.296076
[43]: 6.833670
[44]: -6.493154
[45]: -4.851185
[46]: 4.000828
[47]: -1.777399
[48]: -1.571341
[49]: 4.035012
[50]: 0.190984
[51]: -0.640436


Avarage Pooling Layer 3 Details:
Data: 
[0]: -0.866767
[1]: 1.082219
[2]: 0.227162
[3]: -2.841620
[4]: 5.429064
[5]: -3.843409
[6]: 3.666108
[7]: -4.223471
[8]: 4.611850
[9]: -2.550333
[10]: -0.586221
[11]: 0.809062
[12]: -3255498820713928627953941742309542958859612020293569701655741905289431756262151704830484747678946929047041001251254917958450331335771669072376388898193385186024319624313471083854257064564551145400348823387288491439201188309316050878464.000000
[13]: nan
[14]: nan
[15]: nan
[16]: nan
[17]: 7.879675
[18]: -6.942989
[19]: 1.324436
[20]: -1.362999
[21]: 7.064873
[22]: -5.672170
[23]: 1.111714
[24]: 1.231835
[25]: -0.224726


======================== Convolution Layer Details ========================
Input Size : 54
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : 0.198508

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.087786
              0 |     1 |     -0.404233
              0 |     2 |      0.196341
              1 |     0 |      0.317225
              1 |     1 |      0.057665
              1 |     2 |      0.415311
              2 |     0 |      0.440733
              2 |     1 |      0.063189
              2 |     2 |     -0.381161
              3 |     0 |     -0.374477
              3 |     1 |      0.255699
              3 |     2 |     -0.099536
              4 |     0 |      0.402890
              4 |     1 |     -0.042070
              4 |     2 |      0.488342
              5 |     0 |     -0.336604
              5 |     1 |      0.280419
              5 |     2 |      0.179861
==========================================================================


Output Layer 4 Details:
Data: 
[0]: 6.664939
[1]: 4.045264
[2]: 6.100253
[3]: -0.943795
[4]: 2.527849
[5]: -0.637354
[6]: 11.615787
[7]: 11.377871
[8]: 8.943236
[9]: -4.474288
[10]: -6.590870
[11]: -0.168377
[12]: 5.725052
[13]: 3.868207
[14]: 7.763752
[15]: 6.957166
[16]: 1.900445
[17]: -0.584263
[18]: -0.234672
[19]: 0.283809
[20]: 7.997982
[21]: 0.870537
[22]: 5.677856
[23]: 0.242126
[24]: -12059627040253625572147672600804710767928581901948117215368490538080584264196168874005653119790056755414573110405282149537620235817800831378394113824437278142923325284582478135321317974668629762635368864260016244173348469215058378883072.000000
[25]: -1273016306759300932962550138015397450906060120781746397592821108202847244514327256880241369028742599505067701791949932734007538567680294455581205295661667492012343742433855431225408014259843837627998492095155020441049381817823728238592.000000
[26]: nan
[27]: nan
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: 7.266290
[35]: -1.811948
[36]: -9.011072
[37]: 3.513525
[38]: 0.553569
[39]: 6.137545
[40]: 5.308164
[41]: 3.829017
[42]: 10.268750
[43]: -2.482094
[44]: -7.471432
[45]: 4.054133
[46]: 0.676820
[47]: 6.143381
[48]: 4.480539
[49]: 1.813649
[50]: 2.861565
[51]: 1.664687


Avarage Pooling Layer 4 Details:
Data: 
[0]: 5.355102
[1]: 2.578229
[2]: 0.945248
[3]: 11.496829
[4]: 2.234474
[5]: -3.379624
[6]: 4.796630
[7]: 7.360459
[8]: 0.658091
[9]: 0.024569
[10]: 4.434259
[11]: 2.959991
[12]: -6666321673506463252555111369410054109417321011364931806480655823141715754355248065442947244409399677459820406098616041135813887192740562916987659560049472817467834513508166783273362994464236800131683678177585632307198925516441053560832.000000
[13]: nan
[14]: nan
[15]: nan
[16]: nan
[17]: 2.727171
[18]: -2.748774
[19]: 3.345557
[20]: 4.568591
[21]: 3.893328
[22]: -1.708650
[23]: 3.410100
[24]: 3.147094
[25]: 2.263126


======================== Convolution Layer Details ========================
Input Size : 54
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : -0.432768

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.413114
              0 |     1 |     -0.196951
              0 |     2 |      0.367458
              1 |     0 |      0.464690
              1 |     1 |      0.014115
              1 |     2 |     -0.294671
              2 |     0 |     -0.475311
              2 |     1 |      0.152608
              2 |     2 |      0.215567
              3 |     0 |      0.072863
              3 |     1 |      0.203848
              3 |     2 |     -0.321894
              4 |     0 |      0.225455
              4 |     1 |      0.457640
              4 |     2 |      0.284600
              5 |     0 |      0.295343
              5 |     1 |      0.102283
              5 |     2 |     -0.278100
==========================================================================


Output Layer 5 Details:
Data: 
[0]: 2.146402
[1]: 2.527172
[2]: 8.333946
[3]: 3.194417
[4]: 5.293252
[5]: 5.723590
[6]: -0.430530
[7]: -0.261211
[8]: 9.876152
[9]: 3.383910
[10]: -1.765781
[11]: -0.284748
[12]: 4.296886
[13]: 5.135513
[14]: 0.150428
[15]: 0.040238
[16]: 10.294259
[17]: 2.017877
[18]: -2.809456
[19]: 1.633674
[20]: 6.224341
[21]: 2.738602
[22]: 4.556324
[23]: 2.506423
[24]: 1058640250774650227508232628223329015431264862335491486997852129066920888076157940012375891662171819377278370553083415618003683920081716853104527482130121774962757197393084853636154449193956174730992707241181570083541214120970234626048.000000
[25]: 1373488897104595854059380980184640252505814306708949315675404716257770303985532670837129417845417343993105647907192967643595955730522772531183300121965947742213016458910110201496965108311885626635451520690677054137734263795310464598016.000000
[26]: nan
[27]: nan
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: -1.023653
[35]: 8.831974
[36]: 0.272415
[37]: -5.260945
[38]: 3.410959
[39]: 5.590047
[40]: 2.867574
[41]: -0.323252
[42]: 0.107887
[43]: 9.209491
[44]: 0.265002
[45]: -5.444392
[46]: 3.436544
[47]: 4.258023
[48]: 1.358506
[49]: 4.436211
[50]: 2.064341
[51]: 0.979204


Avarage Pooling Layer 5 Details:
Data: 
[0]: 2.336787
[1]: 5.764182
[2]: 5.508421
[3]: -0.345871
[4]: 6.630031
[5]: -1.025264
[6]: 4.716200
[7]: 0.095333
[8]: 6.156068
[9]: -0.587891
[10]: 4.481472
[11]: 3.531373
[12]: 1216064573939623040783806804203984633968539584522220401336628422662345596030845305424752654753794581685192009230138191630799819825302244692143913802048034758587886828151597527566559778752920900683222113965929312110637738958140349612032.000000
[13]: nan
[14]: nan
[15]: nan
[16]: nan
[17]: 3.904161
[18]: -2.494265
[19]: 4.500503
[20]: 1.272161
[21]: 4.658689
[22]: -2.589695
[23]: 3.847284
[24]: 2.897358
[25]: 1.521773


======================== Convolution Layer Details ========================
Input Size : 54
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : -0.236015

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.058519
              0 |     1 |     -0.480926
              0 |     2 |     -0.108112
              1 |     0 |      0.337062
              1 |     1 |      0.169759
              1 |     2 |      0.090381
              2 |     0 |     -0.197653
              2 |     1 |     -0.444975
              2 |     2 |      0.201071
              3 |     0 |      0.341395
              3 |     1 |     -0.186453
              3 |     2 |     -0.167745
              4 |     0 |     -0.373714
              4 |     1 |     -0.273644
              4 |     2 |      0.381680
              5 |     0 |     -0.156301
              5 |     1 |     -0.209616
              5 |     2 |     -0.398282
==========================================================================


Output Layer 6 Details:
Data: 
[0]: 4.998669
[1]: 5.182907
[2]: 5.300538
[3]: 6.256863
[4]: 3.839466
[5]: 7.730666
[6]: 4.020652
[7]: -0.331784
[8]: 0.781260
[9]: 4.780779
[10]: 4.592072
[11]: 5.760023
[12]: 1.949197
[13]: 4.710650
[14]: 3.751659
[15]: 4.156798
[16]: 0.629496
[17]: 4.287445
[18]: 5.085582
[19]: 5.518580
[20]: 3.382560
[21]: 5.008922
[22]: 3.184360
[23]: 3.645976
[24]: -4235325458311124386629147443077229315845016996468186223567585839930901115912455473254023026448830978965070057802824720835144252159926505526277871475065099107032792562119490661334995694918681763318664542741786419413376418154459336540160.000000
[25]: 166681164192694532149219726615546660800025197294539965092219849034277042762301439738128568519467381014219062980322992002150924762394661208036274293384123284796530264323246067261069839105056799682145415774963528190995317450056096808960.000000
[26]: nan
[27]: nan
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: -0.708229
[35]: 4.645792
[36]: 5.291145
[37]: 2.550214
[38]: 3.227775
[39]: 3.675558
[40]: 3.784706
[41]: -0.213412
[42]: -0.601237
[43]: 4.799203
[44]: 4.141121
[45]: 2.491932
[46]: 4.588227
[47]: 3.250469
[48]: 2.553103
[49]: 2.991290
[50]: 1.892788
[51]: 3.471904


Avarage Pooling Layer 6 Details:
Data: 
[0]: 5.090788
[1]: 5.778701
[2]: 5.785066
[3]: 1.844434
[4]: 2.781020
[5]: 5.176047
[6]: 3.329924
[7]: 3.954228
[8]: 2.458471
[9]: 5.302081
[10]: 4.195741
[11]: 3.415168
[12]: -2034322147059214927239963858230841327522495899586823129237682995448312036575077016757947228964681798975425497411250864416496663698765922159120798590840487911118131148898122297036962927906812481818259563483411445611190550352201619865600.000000
[13]: nan
[14]: nan
[15]: nan
[16]: nan
[17]: 1.968782
[18]: 3.920679
[19]: 3.451666
[20]: 1.785647
[21]: 2.098983
[22]: 3.316526
[23]: 3.919348
[24]: 2.772197
[25]: 2.682346


======================== Convolution Layer Details ========================
Input Size : 54
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : -0.273034

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |      0.337458
              0 |     1 |      0.388943
              0 |     2 |     -0.439238
              1 |     0 |     -0.359828
              1 |     1 |      0.396176
              1 |     2 |      0.309320
              2 |     0 |      0.035783
              2 |     1 |     -0.069323
              2 |     2 |      0.106525
              3 |     0 |      0.246818
              3 |     1 |     -0.426023
              3 |     2 |     -0.406186
              4 |     0 |      0.293451
              4 |     1 |      0.127827
              4 |     2 |     -0.306207
              5 |     0 |     -0.317530
              5 |     1 |      0.474548
              5 |     2 |     -0.129505
==========================================================================


Output Layer 7 Details:
Data: 
[0]: -0.200265
[1]: -6.248674
[2]: 0.689640
[3]: -10.520989
[4]: 5.273351
[5]: -5.523607
[6]: -2.387992
[7]: 6.246991
[8]: -4.332872
[9]: -9.714880
[10]: 3.506325
[11]: -8.703044
[12]: 4.043164
[13]: -2.156461
[14]: -2.833296
[15]: -0.811798
[16]: -0.799478
[17]: -10.226686
[18]: 2.659295
[19]: -1.328570
[20]: -1.845162
[21]: -6.180074
[22]: 1.950531
[23]: -5.540032
[24]: 6909981477014773061875874016175373732360271361317305798546839722260055576919518360852632256662189863332486580192523557011476427303020128647488682066636306772212979426516007987631441536942136998773253267426075568871506703209210086162432.000000
[25]: -2745437306033638723476350093935761547019208751292861318698737061022405450194480952378598418050853147432692220055356185013519531616486081186650913312969897076700177886931571617699621501319009158435740652516391761300856444695950810677248.000000
[26]: nan
[27]: nan
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: -1.924338
[35]: -4.288358
[36]: -4.658342
[37]: 1.497865
[38]: 2.410901
[39]: -4.290844
[40]: -4.458986
[41]: 3.599058
[42]: -5.010770
[43]: -2.443593
[44]: -4.534447
[45]: 1.484867
[46]: 1.767612
[47]: -4.062163
[48]: -3.181966
[49]: -0.176004
[50]: -5.098267
[51]: 1.280229


Avarage Pooling Layer 7 Details:
Data: 
[0]: -3.224469
[1]: -4.915675
[2]: -0.125128
[3]: 1.929500
[4]: -7.023876
[5]: -2.598360
[6]: 0.943352
[7]: -1.822547
[8]: -5.513082
[9]: 0.665363
[10]: -4.012618
[11]: -1.794751
[12]: 2082272085490567169199761961119806092670531305012222239924051330618825063362518704237016919305668357949897180068583685998978447843267023730418884376833204847756400769792218184965910017811563920168756307454841903785325129256629637742592.000000
[13]: nan
[14]: nan
[15]: nan
[16]: nan
[17]: -3.106348
[18]: -1.580239
[19]: -0.939971
[20]: -0.429964
[21]: -3.727182
[22]: -1.524790
[23]: -1.147276
[24]: -1.678985
[25]: -1.909019


======================== Convolution Layer Details ========================
Input Size : 54
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : -0.285394

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |      0.441832
              0 |     1 |     -0.308039
              0 |     2 |     -0.485107
              1 |     0 |     -0.446135
              1 |     1 |     -0.270501
              1 |     2 |      0.377255
              2 |     0 |      0.253410
              2 |     1 |     -0.362941
              2 |     2 |     -0.460875
              3 |     0 |     -0.094440
              3 |     1 |      0.392575
              3 |     2 |      0.260308
              4 |     0 |     -0.091388
              4 |     1 |     -0.004288
              4 |     2 |     -0.221763
              5 |     0 |      0.378719
              5 |     1 |     -0.005570
              5 |     2 |     -0.387692
==========================================================================


Output Layer 8 Details:
Data: 
[0]: 5.553955
[1]: 5.849894
[2]: 2.121396
[3]: 4.180191
[4]: -1.079713
[5]: -2.123195
[6]: -0.225431
[7]: 8.510548
[8]: -0.456381
[9]: -0.363295
[10]: 4.075191
[11]: 7.886151
[12]: 0.781869
[13]: 1.712400
[14]: -1.078859
[15]: 7.007929
[16]: -0.205751
[17]: 1.777618
[18]: 8.301920
[19]: 3.264603
[20]: 1.307857
[21]: 1.146078
[22]: 1.848774
[23]: 1.285410
[24]: -9370134321012875701198727426047089462503496403244030549637134652185696204075215007392272984830218751986843337937944386611569145825151723030216256813463722408920806272513230230014613119212791067567029950841435924296529946851937764769792.000000
[25]: -19107744314312933497633720157260686607243223273158953073854210150208871796046519045606788333186438981834535519264863326656818831610739946517998279384978840331800122767424529702155537584290911175240260518650696952625291219318674877841408.000000
[26]: nan
[27]: nan
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: 7.709182
[35]: -0.645264
[36]: -0.975432
[37]: 10.244924
[38]: 0.739646
[39]: -5.432177
[40]: 0.764032
[41]: 3.066251
[42]: 6.836241
[43]: -0.727556
[44]: -0.706494
[45]: 10.113126
[46]: 1.173317
[47]: -1.734809
[48]: 3.054570
[49]: 1.729093
[50]: 2.074373
[51]: 2.649703


Avarage Pooling Layer 8 Details:
Data: 
[0]: 5.701924
[1]: 3.150794
[2]: -1.601454
[3]: 4.142558
[4]: -0.409838
[5]: 5.980671
[6]: 1.247134
[7]: 2.964535
[8]: 0.785933
[9]: 5.783261
[10]: 1.226968
[11]: 1.567092
[12]: -14238939317662903893412734114599513797596149287044525973907194438302902829210384310826073068708703890442209179793904613909727614146946690243283051629623544463722192398232353358386052481072820978245627111570184507521570713376673729871872.000000
[13]: nan
[14]: nan
[15]: nan
[16]: nan
[17]: 3.531959
[18]: 4.634746
[19]: -2.346266
[20]: 1.915141
[21]: 3.054343
[22]: 4.703316
[23]: -0.280746
[24]: 2.391831
[25]: 2.362038


======================== Convolution Layer Details ========================
Input Size : 54
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : -0.330500

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.013321
              0 |     1 |     -0.406674
              0 |     2 |     -0.474303
              1 |     0 |     -0.091510
              1 |     1 |      0.409360
              1 |     2 |     -0.107562
              2 |     0 |      0.186850
              2 |     1 |      0.470641
              2 |     2 |      0.424436
              3 |     0 |     -0.270928
              3 |     1 |      0.072344
              3 |     2 |     -0.495422
              4 |     0 |     -0.379910
              4 |     1 |      0.141804
              4 |     2 |      0.157094
              5 |     0 |      0.314905
              5 |     1 |     -0.104175
              5 |     2 |      0.493408
==========================================================================


Output Layer 9 Details:
Data: 
[0]: -3.435575
[1]: 1.813358
[2]: -6.930259
[3]: -1.293085
[4]: -1.571733
[5]: 3.368116
[6]: 4.809864
[7]: 5.902949
[8]: -11.533425
[9]: -9.084144
[10]: -3.707092
[11]: 3.760090
[12]: 1.889922
[13]: -0.885472
[14]: -1.276749
[15]: 2.224531
[16]: -4.852160
[17]: -10.357393
[18]: 0.902926
[19]: 2.007970
[20]: -2.810741
[21]: 0.950477
[22]: -2.219038
[23]: 1.395601
[24]: 5031986237987375266145730290657952066318916424277914249759492146210346320612619281570921173867997674419994494311266384926443442733359884840910588956943430186509168612975508091942974194634792441098600094661623051633279511970401776304128.000000
[25]: 1068378109988368952939106566074013278769111920254357580364718766290955334746118336547424129901876510292588987788983963405872343962798185852731274087689423644179938664915601513531011266022498184956641825537028408215639776732770868396032.000000
[26]: nan
[27]: nan
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: -5.866196
[35]: -7.162023
[36]: -5.222432
[37]: 3.125047
[38]: 5.534225
[39]: -3.267619
[40]: 5.344039
[41]: 0.017115
[42]: -5.701739
[43]: -5.893270
[44]: -6.592643
[45]: 2.162226
[46]: 4.442235
[47]: -3.613320
[48]: 2.160013
[49]: -2.365274
[50]: -2.669886
[51]: -2.331166


Avarage Pooling Layer 9 Details:
Data: 
[0]: -0.811109
[1]: -4.111672
[2]: 0.898191
[3]: 5.356407
[4]: -10.308784
[5]: 0.026499
[6]: 0.502225
[7]: 0.473891
[8]: -7.604776
[9]: 1.455448
[10]: -0.930132
[11]: -0.411719
[12]: 3050182173987872109542418428365982672544014172266135915062105456250650827679368809059172651884937092356291741050125174166157893348079035346820931522316426915344553638945554802736992730328645313027620960099325729924459644351586322350080.000000
[13]: nan
[14]: nan
[15]: nan
[16]: nan
[17]: -6.514109
[18]: -1.048692
[19]: 1.133303
[20]: 2.680577
[21]: -5.797505
[22]: -2.215209
[23]: 0.414458
[24]: -0.102631
[25]: -2.500526


======================== Convolution Layer Details ========================
Input Size : 54
Kernel Size: 3
Stride     : 1
Filter Size: 10
Bias       : -0.257042

----------------------------- Weights -----------------------------------
Input Dimension | Index |   Weight     
-------------------------------------------------------------
              0 |     0 |     -0.234428
              0 |     1 |     -0.488403
              0 |     2 |     -0.052355
              1 |     0 |     -0.213401
              1 |     1 |     -0.179708
              1 |     2 |     -0.407437
              2 |     0 |     -0.419095
              2 |     1 |      0.424528
              2 |     2 |     -0.204611
              3 |     0 |      0.494812
              3 |     1 |     -0.090655
              3 |     2 |     -0.218711
              4 |     0 |      0.357143
              4 |     1 |     -0.061235
              4 |     2 |      0.113758
              5 |     0 |     -0.212455
              5 |     1 |     -0.205771
              5 |     2 |      0.316584
==========================================================================


Output Layer 10 Details:
Data: 
[0]: 2.226653
[1]: 4.969121
[2]: 7.012541
[3]: 3.743401
[4]: 4.731086
[5]: 6.091450
[6]: -0.822075
[7]: 5.465270
[8]: 7.023906
[9]: 0.883615
[10]: 4.842152
[11]: -1.777430
[12]: 5.268808
[13]: 6.028995
[14]: 2.459969
[15]: 2.525108
[16]: 5.074195
[17]: 5.176530
[18]: -1.064278
[19]: 8.768628
[20]: 0.747031
[21]: 5.393912
[22]: 2.427798
[23]: 4.441255
[24]: -5883772796062575711613896059218465354206511923077805425489226993882846861523389850751514654708046850813476647968589646216585691087436352613032679643431223322128488710463131141495994892119002448837905318228912115738600474729182264295424.000000
[25]: 2189322879791799866871274243293682851338290903149182846661729433405551141827457908892930264049545997715768849055040635124077816865481517546143811421042551280830088281623285240832038936259635847467324534117195366979479515087504802840576.000000
[26]: nan
[27]: nan
[28]: nan
[29]: nan
[30]: nan
[31]: nan
[32]: nan
[33]: nan
[34]: 4.286516
[35]: 2.017777
[36]: 6.692097
[37]: -3.166219
[38]: 5.391566
[39]: 3.129071
[40]: -1.564907
[41]: 4.665500
[42]: 1.957096
[43]: 3.234598
[44]: 7.431968
[45]: -3.415259
[46]: 7.085995
[47]: 2.201411
[48]: 0.743509
[49]: 4.106008
[50]: 2.463435
[51]: 2.913042


Avarage Pooling Layer 10 Details:
Data: 
[0]: 3.597887
[1]: 5.377971
[2]: 5.411268
[3]: 2.321598
[4]: 3.953760
[5]: 1.532361
[6]: 5.648901
[7]: 2.492538
[8]: 5.125362
[9]: 3.852175
[10]: 3.070472
[11]: 3.434526
[12]: -1847224958135387922371310907962391251434110509964311289413748780238647859847965970929292195329250426548853899456774505546253937110977417533444434111194336020649200214419922950331977977929683300685290392055858374379560479820838730727424.000000
[13]: nan
[14]: nan
[15]: nan
[16]: nan
[17]: 3.152146
[18]: 1.762939
[19]: 4.260319
[20]: 1.550296
[21]: 2.595847
[22]: 2.008355
[23]: 4.643703
[24]: 2.424759
[25]: 2.688238

